

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>1. Pipeline-old (pipeline-old)</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon-umich.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/my_theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../index.html"/>
        <link rel="up" title="MLLib - Main guide (apache-ml-guide.rst)" href="apache-ml-guide.html"/>
        <link rel="next" title="2. Extracting, transforming and selecting features (et-fs)" href="apache-ml-guide.et-fs.html"/>
        <link rel="prev" title="MLLib - Main guide (apache-ml-guide.rst)" href="apache-ml-guide.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Coding Notebook
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents (PySpark)</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="top-pyspark.html">PySpark Notes (<code class="docutils literal"><span class="pre">top-pyspark.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pyspark-snippet.html">1. <code class="docutils literal"><span class="pre">pyspark-snippet.rst</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#modules">1.1. Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#create-toy-dataset">1.2. Create toy dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#print-rdd-per-item">1.3. Print RDD per item</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#databrick-helper-function-displaying-all-dfs-in-the-notebook">1.4. Databrick helper function displaying all DFs in the notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#get-shape-of-df-gotta-be-a-better-way">1.5. Get shape of DF (gotta be a better way)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pyspark-practice.html">2. <code class="docutils literal"><span class="pre">pyspark-practice.rst</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#basics-dfs">2.1. Basics DFs</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#udfs">2.2. UDFs</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#sorting">2.3. Sorting</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#create-df-from-list-of-tuples">2.4. Create DF from list of tuples</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#groupby">2.5. groupby</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#practice-with-faker-data">2.6. Practice with faker data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-practice.html#little-refrehser-on-generators">2.6.1. Little refrehser on generators</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#register-table-to-use-sql">2.7. Register table to use SQL</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#more">2.8. More</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pyspark-overflow.html">3. <code class="docutils literal"><span class="pre">pyspark-overflow.rst</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#how-to-get-a-value-from-the-row-object-in-spark-dataframe">3.1. How to get a value from the Row object in Spark Dataframe?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#how-to-add-a-constant-column-in-a-spark-dataframe">3.2. How to add a constant column in a Spark DataFrame?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#add-an-empty-column-to-spark-dataframe">3.3. Add an empty column to Spark DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#count-number-of-non-nan-entries-in-each-column-of-spark-dataframe">3.4. Count number of non-NaN entries in each column of Spark dataframe</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#use-simple-aggregation">3.4.1. Use simple aggregation</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#use-sql-null-semantics">3.4.2. Use SQL <code class="docutils literal"><span class="pre">NULL</span></code> semantics</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#in-fractions">3.4.3. In fractions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#updating-a-dataframe-column-in-spark">3.5. Updating a dataframe column in spark</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#how-do-i-add-a-new-column-to-spark-data-frame-pyspark">3.6. How do I add a new column to spark data frame (Pyspark)?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#use-literals-lit">3.6.1. Use literals <code class="docutils literal"><span class="pre">lit</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#transforming-an-existing-column">3.6.2. Transforming an existing column</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#using-join">3.6.3. Using <code class="docutils literal"><span class="pre">join</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#using-function-udf">3.6.4. Using function/UDF</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#how-to-change-dataframe-column-names-in-pyspark">3.7. How to change dataframe column names in pyspark?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#option-1-using-selectexpr">3.7.1. Option 1. Using selectExpr.</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#option-2-using-withcolumnrenamed">3.7.2. Option 2. Using <code class="docutils literal"><span class="pre">withColumnRenamed</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#using-alias">3.7.3. Using alias</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#using-sqlcontext-sql">3.7.4. Using <code class="docutils literal"><span class="pre">sqlContext.sql</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#pyspark-dataframes-way-to-enumerate-without-converting-to-pandas">3.8. PySpark DataFrames - way to enumerate without converting to Pandas?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#ones-i-just-bookmarked-for-future-reference">3.9. Ones I just bookmarked for future reference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#reshaping-pivoting-data-in-spark-rdd-and-or-spark-dataframes">3.9.1. Reshaping/Pivoting data in Spark RDD and/or Spark DataFrames</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pyspark-install.html">4. Install PySpark (<code class="docutils literal"><span class="pre">pyspark-install</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-install.html#windows">4.1. windows?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-install.html#retry-above-is-a-clusterfuck">4.2. Retry, above is a clusterfuck</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-prog-guide-rdd.html">5. (todo) Spark Programming Guide (<code class="docutils literal"><span class="pre">apache-prog-guide-rdd</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="apache-prog-guide-df.html">6. Spark Programming Guide DataFrames (<code class="docutils literal"><span class="pre">apache-prog-guide-df</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#overview">6.1. Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#sql">6.1.1. SQL</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#datasets-and-dataframes">6.1.2. Datasets and DataFrames</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#getting-started">6.2. Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#starting-point-sparksession">6.2.1. Starting Point: <code class="docutils literal"><span class="pre">SparkSession</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#creating-dataframes">6.2.2. Creating DataFrames</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#untyped-dataset-operations-aka-dataframe-operations">6.2.3. Untyped Dataset Operations (aka DataFrame Operations)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#running-sql-queries-programmatically">6.2.4. Running SQL Queries Programmatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#creating-datasets-only-in-scala-java">6.2.5. Creating Datasets (only in Scala/Java)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#interoperating-with-rdds">6.2.6. Interoperating with RDDs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#data-sources">6.3. Data Sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#generic-load-functions">6.4. Generic Load Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#default-parquet">6.4.1. Default (parquet)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#manually-specifying-options">6.4.2. Manually Specifying Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#run-sql-on-files-directly">6.4.3. Run SQL on files directly</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#generic-save-functions">6.5. Generic Save Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#save-modes">6.5.1. Save Modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#saving-to-persistent-tables">6.5.2. __Saving to Persistent Tables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#parquet-files">6.6. Parquet Files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#loading-data-programmatically">6.6.1. Loading Data Programmatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#partition-discovery">6.6.2. __Partition Discovery</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#schema-merging">6.6.3. Schema Merging</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#hive-metastore-parquet-conversion">6.6.4. __Hive metastore Parquet Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#configuration">6.6.5. Configuration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#json-datasets">6.7. JSON Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#hive-tables">6.8. Hive Tables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#interacting-with-different-versions-of-hive-metastore">6.8.1. __Interacting with Different Versions of Hive Metastore</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#jdbc-to-other-databases">6.9. __JDBC To Other Databases</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#performance-tuning">6.10. Performance Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#caching-data-in-memory">6.10.1. Caching Data in Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#other-configuration-options">6.10.2. Other Configuration Options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#distributed-sql-engine">6.11. Distributed SQL Engine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#running-the-thrift-jdbc-odbc-server">6.11.1. __Running the Thrift JDBC/ODBC server</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#running-the-spark-sql-cli">6.11.2. Running the Spark SQL CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-prog-guide-df.html#reference">6.12. Reference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#data-types">6.12.1. Data-Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-prog-guide-df.html#nan-semantics">6.12.2. NaN Semantics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="databricks.html">7. Databrick Doc (<code class="docutils literal"><span class="pre">databricks.rst</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="databricks.html#ml-stuffs">7.1. ML Stuffs</a></li>
<li class="toctree-l3"><a class="reference internal" href="databricks.html#bunch-of-notebooks">7.2. Bunch of notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="top-edx.html">EdX Course Notes (<code class="docutils literal"><span class="pre">top-edx.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab0.html">1. cs105_lab0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab0.html#create-dataframe-and-filter-it">1.1. Create DataFrame and filter it</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab0.html#load-a-text-file">1.2. Load a text file</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab0.html#check-plotting">1.3. Check plotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab1a.html">2. cs105_lab1a</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a.html#spark-context">2.1. Spark Context</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a.html#sparkcontext-and-the-driver-program-cluster-structure">2.2. SparkContext and the Driver Program (Cluster Structure)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#about-the-driver-program">2.2.1. About the Driver Program</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#about-hivecontext-the-type-of-sqlcontext-for-db">2.2.2. About HiveContext (the type of sqlContext for DB)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#sparkcontext">2.2.3. SparkContext</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a.html#using-dataframes-and-chaining-transformations">2.3. Using DataFrames and chaining transformations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#dataframe-and-schema">2.3.1. DataFrame and Schema</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#ways-to-define-schemas">2.3.2. Ways to define schemas</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#distributed-data-and-using-a-collection-to-create-a-dataframe">2.3.3. Distributed Data and using a collection to create a DataFrame</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#query-plans-and-the-catalyst-optimizer">2.3.4. Query plans and the <code class="docutils literal"><span class="pre">Catalyst</span> <span class="pre">Optimizer</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab1a_coding.html">3. cs105_lab1a codes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#exercise-overview">3.1. Exercise Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#create-list-of-data">3.2. Create list of Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#create-dataframe-from-a-list">3.3. Create DataFrame from a list</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#subtract-one-from-each-the-age-row">3.4. Subtract one from each the <em>age</em> row</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#apply-transformations-and-examine-query-plan">3.5. Apply transformations, and examine query plan</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#use-collect-to-view-results">3.6. Use <code class="docutils literal"><span class="pre">collect</span></code> to view results</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#display-helper-function-in-db">3.7. display helper function in DB</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#more-actions-count-to-get-total">3.8. More actions: <code class="docutils literal"><span class="pre">count</span></code> to get total</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#apply-transformation-filter-and-view-results-with-collect">3.9. Apply transformation <code class="docutils literal"><span class="pre">filter</span></code> and view results with <code class="docutils literal"><span class="pre">collect</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#lambda-functions-and-udfs">3.10. Lambda functions and UDFs</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#additional-dataframe-actions">3.11. Additional DataFrame actions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#additional-dataframe-transformations">3.12. Additional DataFrame transformations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#orderby">3.12.1. orderBy</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#a-distinct-and-dropduplicates">3.12.2. A <code class="docutils literal"><span class="pre">distinct</span></code> and <code class="docutils literal"><span class="pre">dropDuplicates</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#drop">3.12.3. drop</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#groupby">3.12.4. groupBy</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#sample">3.12.5. sample</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#caching-dataframes-and-storage-options">3.13. Caching DataFrames and Storage Options</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#unpersist-and-storage-options">3.13.1. Unpersist and storage options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#debugging-spark-applications-and-lazy-evaluation">3.14. Debugging Spark applications and lazy evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#jvm-and-py4j-how-python-is-executed-in-spark">3.14.1. JVM and Py4J - How Python is Executed in Spark</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#challenges-with-lazy-evaluation-using-transformations-and-actions">3.14.2. Challenges with lazy evaluation using transformations and actions</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#finding-the-bug">3.14.3. Finding the bug</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#moving-toward-expert-style">3.14.4. Moving toward expert style</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab1b.html">4. cs105_lab1b_wordcount</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#create-a-base-df-and-perform-operations">4.1. Create a base DF and perform operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#create-a-base-df">4.1.1. Create a base DF</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#use-df-functions-to-add-an-s">4.1.2. Use DF functions to add an &#8216;s&#8217;</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#length-of-each-word">4.1.3. Length of each word</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#counting-with-spark-sql-and-dataframes">4.2. Counting with Spark SQL and DataFrames</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#using-groupby-and-count">4.2.1. Using groupBy and count</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#finding-unique-words-and-a-mean-value">4.3. Finding unique words and a mean value</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#unique-words">4.3.1. Unique words</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#means-of-groups-using-dataframes">4.3.2. Means of groups using DataFrames</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#apply-word-count-to-a-file">4.4. Apply word count to a file</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#the-wordcount-function">4.4.1. The wordCount function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#capitalization-and-punctuation">4.4.2. Capitalization and punctuation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#load-a-text-file">4.4.3. Load a text file</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#words-from-lines">4.4.4. Words from lines</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#count-the-words">4.4.5. Count the words</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#random-stuffs-i-played-around-with">4.5. Random stuffs I played around with</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab2.html">5. cs105_lab2_apache_log</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#introduction-and-imports">5.1. Introduction and Imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#exploratory-data-analysis">5.2. Exploratory Data Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#b-parsing-the-log-file">5.2.1. (2b) Parsing the log file</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#data-cleaning">5.2.2. Data Cleaning</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#fix-the-rows-with-null-content-size">5.2.3. Fix the rows with null content_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#parsing-the-timestamp">5.2.4. Parsing the timestamp</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#analysis-walk-through-on-the-web-server-log-file">5.3. Analysis Walk-Through on the Web Server Log File</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#example-content-size-statistics">5.3.1. Example: Content Size Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#example-http-status-analysis">5.3.2. Example: HTTP Status Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#example-status-graphing">5.3.3. Example: Status Graphing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#example-frequent-hosts">5.3.4. Example: Frequent Hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#example-visualizing-paths">5.3.5. Example: Visualizing Paths</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#example-top-paths">5.3.6. Example: Top Paths</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#analyzing-web-server-log-file">5.4. Analyzing Web Server Log File</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-top-ten-error-paths-hw-problem">5.4.1. Exercise: Top Ten Error Paths (HW Problem)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-number-of-unique-hosts-hw">5.4.2. Exercise: Number of Unique Hosts (HW)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-number-of-unique-daily-hosts">5.4.3. Exercise: Number of Unique Daily Hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-visualizing-the-number-of-unique-daily-hosts">5.4.4. Exercise: Visualizing the Number of Unique Daily Hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-average-number-of-daily-requests-per-host">5.4.5. Exercise: Average Number of Daily Requests per Host</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-visualizing-the-average-daily-requests-per-unique-host">5.4.6. Exercise: Visualizing the Average Daily Requests per Unique Host</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#exploring-404-status-codes">5.5. Exploring 404 Status Codes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-counting-404-response-codes">5.5.1. Exercise: Counting 404 Response Codes</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-listing-404-status-code-records">5.5.2. Exercise: Listing 404 Status Code Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-listing-the-top-twenty-404-response-code-paths">5.5.3. Exercise: Listing the Top Twenty 404 Response Code paths</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-listing-the-top-twenty-five-404-response-code-hosts">5.5.4. Exercise: Listing the Top Twenty-five 404 Response Code Hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-listing-404-errors-per-day">5.5.5. Exercise: Listing 404 Errors per Day</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-visualizing-the-404-errors-by-day">5.5.6. Exercise: Visualizing the 404 Errors by Day</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-top-five-days-for-404-errors">5.5.7. Exercise: Top Five Days for 404 Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-hourly-404-errors">5.5.8. Exercise: Hourly 404 Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#exercise-visualizing-the-404-response-codes-by-hour">5.5.9. Exercise: Visualizing the 404 Response Codes by Hour</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs110_lab1.html">6. cs110_lab1_power_ml_pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#background">6.1. Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#background-power-generation">6.1.1. Background &#8212; power generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#challenge-for-power-grid-operation">6.1.2. Challenge for power grid operation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#the-business-problem">6.1.3. The business problem</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#business-understanding">6.2. Business Understanding</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#extract-transform-load-etl-your-data">6.3. Extract-Transform-Load (ETL) Your Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-2a">6.3.1. Exercise 2a</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-2b">6.3.2. Exercise 2b</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-2c">6.3.3. Exercise 2c</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-2d">6.3.4. Exercise 2d</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#explore-your-data">6.4. Explore your data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#a">6.4.1. 3a</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#b">6.4.2. 3b</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#visualize-your-data">6.5. Visualize your data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#id1">6.5.1. 4a</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-4-b">6.5.2. Exercise 4(b)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#excercise-4-c">6.5.3. Excercise 4(c)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-4-d">6.5.4. Exercise 4(d)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#data-preparation-where-i-left-off">6.6. Data Preparation (where i left off)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-5-a">6.6.1. Exercise 5(a)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#data-modeling">6.7. Data Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-6-a">6.7.1. Exercise 6(a)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#id2">6.7.2. 6(b)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#c">6.7.3. 6(c)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#d">6.7.4. 6(d)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#e">6.7.5. 6e</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#f">6.7.6. 6(f)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#g">6.7.7. 6(g)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#h">6.7.8. 6(h)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#i">6.7.9. 6(i)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#j">6.7.10. 6(j)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#k">6.7.11. 6(k)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#tuning-and-evaluation">6.8. Tuning and Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#id3">6.8.1. 7(a)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-b">6.8.2. Exercise 7(b)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-c-decisiontreeregressor">6.8.3. Exercise 7(c) DecisionTreeRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-d">6.8.4. Exercise 7(d)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-e">6.8.5. Exercise 7(e)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-f-random-forest-regressor">6.8.6. Exercise 7(f) (Random Forest Regressor)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-g-cross-validation">6.8.7. Exercise 7(g) (cross validation)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-h-model-evaluation">6.8.8. Exercise 7(h) (model evaluation)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs110_lab2.html">7. cs110_lab2_als_prediction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab2.html#preliminaries">7.1. Preliminaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#the-20-million-movie-sample">7.1.1. The 20-million movie sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#cpu-vs-io-tradeoff">7.1.2. CPU vs IO Tradeoff</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#load-and-cache">7.1.3. Load and Cache</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab2.html#basic-recommendations">7.2. Basic Recommendations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-1a-movies-with-highest-average-ratings">7.2.1. Exercise (1a) Movies with Highest Average Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-1b-movies-with-highest-average-ratings-and-at-least-500-reviews">7.2.2. Exercise (1b) Movies with Highest Average Ratings and at least 500 reviews</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab2.html#collaborative-filtering">7.3. Collaborative Filtering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-2a-creating-a-training-set">7.3.1. Exercise (2a) Creating a Training Set</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-2b-alternating-least-squares">7.3.2. Exercise (2b) Alternating Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#why-are-we-doing-our-own-cross-validation">7.3.3. Why are we doing our own cross-validation?</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#excersie-2c-testing-your-model">7.3.4. Excersie (2c) Testing Your Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-2d-comparing-your-model">7.3.5. Exercise (2d) Comparing Your Model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab2.html#predictions-for-yourself">7.4. Predictions for Yourself</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3a-your-movie-ratings">7.4.1. Exercise (3a) Your Movie Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3b-add-your-movies-to-training-dataset">7.4.2. Exercise (3b) Add Your Movies to Training Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3c-train-a-model-with-your-ratings">7.4.3. Exercise (3c) Train a Model with Your Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3d-check-rmse-for-the-new-model-with-your-ratings">7.4.4. Exercise (3d) Check RMSE for the New Model with Your Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3e-predict-your-ratings">7.4.5. Exercise (3e) Predict Your Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3f-predict-your-ratings">7.4.6. Exercise (3f) Predict Your Ratings</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs110_lab3a.html">8. cs110_lab3a_word_count_rdd</a></li>
<li class="toctree-l2"><a class="reference internal" href="cs110_lab3b.html">9. cs110_lab3b_text_analysis_ER</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#data-files">9.1. Data files</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#preliminaries">9.2. Preliminaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#load-data-files">9.2.1. Load data files</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#examine-the-lines-loaded">9.2.2. Examine the lines loaded</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#er-as-text-similarity-bags-of-words">9.3. ER as Text Similarity - Bags of Words</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-1-a-tokenize-a-string">9.3.1. Exercise 1(a) Tokenize a String</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-1b-removing-stopwords">9.3.2. Exercise (1b) removing stopwords</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-1c-tokenizing-the-small-datasets">9.3.3. Exercise (1c) Tokenizing the small datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-1d-amazon-record-with-the-most-tokens">9.3.4. Exercise (1d) Amazon record with the most tokens</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#er-as-text-similarity-weighted-bag-of-words-using-tf-idf">9.4. ER as Text Similarity - Weighted Bag-of-Words using TF-IDF</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-2a-implement-a-tf-function">9.4.1. Exercise (2a) Implement a TF function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-2b-create-a-corpus">9.4.2. Exercise (2b) Create a corpus</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-2c-implement-an-idfs-function">9.4.3. Exercise (2c) Implement an IDFs function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-2d-tokens-with-the-smallest-idf">9.4.4. Exercise (2d) Tokens with the smallest IDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-2e-idf-histogram">9.4.5. Exercise (2e) IDF Histogram</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-2f-implement-a-tf-idf-function">9.4.6. Exercise (2f) Implement a TF-IDF function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#er-as-text-similarity-cosine-similarity">9.5. ER as Text Similarity &#8212; Cosine Similarity</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#excercise-3a-implement-the-components-of-a-cosinesimilarity-function">9.5.1. Excercise (3a) Implement the components of a cosineSimilarity function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-3b-implement-a-cosinesimilarity-function">9.5.2. Exercise (3b) Implement a cosineSimilarity function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-3c-perform-entity-resolution">9.5.3. Exercise (3c) Perform Entity Resolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-3d-perform-entity-resolution-with-broadcast-variables">9.5.4. Exercise (3d) Perform Entity Resolution with Broadcast Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#e-perform-a-gold-standard-evaluation">9.5.5. (3e) Perform a Gold Standard evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#using-the-gold-standard-data-we-can-answer-the-following-questions">9.5.6. Using the &#8220;gold standard&#8221; data we can answer the following questions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#scalable-er">9.6. Scalable ER</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-4a-tokenize-the-full-dataset">9.6.1. Exercise (4a) Tokenize the full dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-4b-compute-idfs-and-tf-idfs-for-the-full-datasets">9.6.2. Exercise (4b) Compute IDFs and TF-IDFs for the full datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-4c-compute-norms-for-the-weights-from-the-full-datasets">9.6.3. Exercise (4c) Compute Norms for the weights from the full datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-4d-create-inverted-indices-from-the-full-datasets">9.6.4. Exercise (4d) Create inverted indices from the full datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-4e-identify-common-tokens-from-the-full-dataset">9.6.5. Exercise (4e) Identify common tokens from the full dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-4f-identify-common-tokens-from-the-full-dataset">9.6.6. Exercise (4f) Identify common tokens from the full dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#analysis">9.7. Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#exercise-5a-counting-true-positives-false-positives-and-false-negatives">9.7.1. Exercise (5a) Counting True Positives, False Positives, and False Negatives</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#b-precision-recall-and-f-measures">9.7.2. 5b Precision, Recall, and F-measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#c-line-plots">9.7.3. 5c Line Plots</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab1a.html">10. cs120_lab1a_math_review</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1a.html#math-review">10.1. Math review</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-1a-scalar-multiplication-vectors">10.1.1. Exercise (1a) Scalar multiplication: vectors</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-1b-element-wise-multiplication-vectors">10.1.2. Exercise (1b) Element-wise multiplication: vectors</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-1c-dot-product">10.1.3. Exercise (1c) Dot product</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-1d-matrix-multiplication">10.1.4. Exercise (1d) Matrix multiplication</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1a.html#numpy">10.2. NumPy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-2a-scalar-multiplication">10.2.1. Exercise (2a) Scalar multiplication</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-2b-element-wise-multiplication-and-dot-product">10.2.2. Exercise (2b) Element-wise multiplication and dot product</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-2c-matrix-math">10.2.3. Exercise (2c) Matrix math</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1a.html#additional-numpy-and-spark-linear-algebra">10.3. Additional NumPy and Spark linear algebra</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-3a-slices">10.3.1. Exercise (3a) Slices</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-3b-combining-ndarray-objects">10.3.2. Exercise (3b) Combining ndarray objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-3c-pyspark-s-densevector">10.3.3. Exercise (3c) PySpark&#8217;s DenseVector</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1a.html#python-lambda-expressions">10.4. Python lambda expressions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4a-lambda-is-an-anonymous-function">10.4.1. Exercise (4a) Lambda is an anonymous function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4b-lambda-fewer-steps-than-def">10.4.2. Exercise (4b) lambda fewer steps than def</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4c-lambda-expression-arguments">10.4.3. Exercise (4c) Lambda expression arguments</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4d-restrictions-on-lambda-expressions">10.4.4. Exercise (4d) Restrictions on lambda expressions</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4e-functional-programming">10.4.5. Exercise (4e) Functional programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4f-composability">10.4.6. Exercise (4f) Composability</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab1b.html">11. cs120_lab1b_word_count_rdd</a></li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab2.html">12. cs120_lab2_linear_regression_df</a></li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab3.html">13. cs120_lab3_ctr_df</a></li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab4.html">14. cs120_lab4_pca</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab4.html#work-through-the-steps-of-pca-on-a-sample-dataset">14.1. Work through the steps of PCA on a sample dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-1-two-dimensional-gaussians">14.1.1. Visualization 1: Two-dimensional Gaussians</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#a-interpreting-pca">14.1.2. 1a) Interpreting PCA</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#b-sample-covariance-matrix">14.1.3. 1b) Sample covariance matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#c-covariance-function">14.1.4. 1c) Covariance Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#d-eigendecomposition">14.1.5. 1d) Eigendecomposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#e-pca-scores">14.1.6. 1e) PCA scores</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab4.html#write-a-pca-function-and-evaluate-pca-on-sample-datasets">14.2. Write a PCA function and evaluate PCA on sample datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#a-pca-function">14.2.1. 2a) PCA function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#b-pca-on-data-random">14.2.2. 2b) PCA on data_random</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-2-pca-projection">14.2.3. Visualization 2: PCA projection</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-3-three-dimensional-data">14.2.4. Visualization 3: Three-dimensional data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#c-3d-to-2d">14.2.5. 2c) 3D to 2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-4-2d-representation-of-3d-data">14.2.6. Visualization 4: 2D representation of 3D data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#d-variance-explained">14.2.7. 2d) Variance explained</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab4.html#parse-inspect-and-preprocess-neuroscience-data-then-perform-pca">14.3. Parse, inspect, and preprocess neuroscience data then perform PCA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#a-load-neuroscience-data">14.3.1. 3a) Load neuroscience data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#b-parse-the-data">14.3.2. 3b) Parse the data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#c-min-and-max-fluorescence">14.3.3. 3c) Min and max fluorescence</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-5-pixel-intensity">14.3.4. Visualization 5: Pixel intensity</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#d-fractional-signal-change">14.3.5. 3d) Fractional signal change</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-6-normalized-data">14.3.6. Visualization 6: Normalized data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#e-pca-on-the-scaled-data">14.3.7. 3e) PCA on the scaled data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-7-top-two-components-as-images">14.3.8. Visualization 7: Top two components as images</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-8-top-two-components-as-one-image">14.3.9. Visualization 8: Top two components as one image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab4.html#feature-based-aggregation-and-pca">14.4. Feature-based aggregation and PCA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#a-aggregation-using-arrays">14.4.1. (4a) Aggregation using arrays</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#b-recreate-with-np-tile-and-np-eye">14.4.2. (4b) Recreate with np.tile and np.eye</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#c-recreate-with-np-kron">14.4.3. (4c) Recreate with np.kron</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#d-aggregate-by-time">14.4.4. (4d) Aggregate by time</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#e-obtain-a-compact-representation">14.4.5. (4e) Obtain a compact representation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-9-top-two-components-by-time">14.4.6. Visualization 9: Top two components by time</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#f-aggregate-by-direction">14.4.7. (4f) Aggregate by direction</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#g-compact-representation-of-direction-data">14.4.8. (4g) Compact representation of direction data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-10-top-two-components-by-direction">14.4.9. Visualization 10: Top two components by direction</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="apache-ml-guide.html">MLLib - Main guide (<code class="docutils literal"><span class="pre">apache-ml-guide.rst</span></code>)</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="">1. Pipeline-old (<code class="docutils literal"><span class="pre">pipeline-old</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#main-concepts-in-pipelines">1.1. Main concepts in Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataframe">1.2. DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pipeline-components">1.3. Pipeline components</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#transformers">1.3.1. Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#estimators">1.3.2. Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="#properties-of-pipeline-components">1.3.3. Properties of pipeline components</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pipeline-transformers-and-estimators">1.4. Pipeline (transformers and estimators)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#how-it-works">1.4.1. How it works</a></li>
<li class="toctree-l4"><a class="reference internal" href="#details">1.4.2. Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#parameters">1.5. Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#saving-and-loading-pipelines">1.6. Saving and Loading Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="#code-examples">1.7. Code Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#estimator-transformer-and-param">1.7.1. Estimator, Transformer, and Param</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-pipeline">1.7.2. Example: Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-model-selection-via-cv-scala">1.7.3. Example: model selection via CV (Scala)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-model-selection-via-train-validation-split-scala">1.7.4. Example: model selection via train validation split (scala)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.et-fs.html">2. Extracting, transforming and selecting features (<code class="docutils literal"><span class="pre">et-fs</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.et-fs.html#feature-extractors">2.1. Feature Extractors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#tf-idf">2.1.1. TF-IDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#word2vec">2.1.2. Word2Vec</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#countvectorizer">2.1.3. CountVectorizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.et-fs.html#feature-transformers">2.2. Feature Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#tokenizer">2.2.1. Tokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#stopwordsremover">2.2.2. StopWordsRemover</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#n-gram">2.2.3. n-gram</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#binarizer">2.2.4. Binarizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#pca">2.2.5. PCA</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#polynomialexpansion">2.2.6. PolynomialExpansion</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#discrete-cosine-transform-dct">2.2.7. Discrete Cosine Transform (DCT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#stringindexer">2.2.8. StringIndexer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#indextostring">2.2.9. IndexToString</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#onehotencoder">2.2.10. OneHotEncoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#vectorindexer">2.2.11. VectorIndexer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#normalizer">2.2.12. Normalizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#standardscaler">2.2.13. StandardScaler</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#minmaxscaler">2.2.14. MinMaxScaler</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#maxabsscaler">2.2.15. MaxAbsScaler</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#bucketizer">2.2.16. Bucketizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#elementwiseproduct-bm">2.2.17. ElementwiseProduct (bm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#sqltransformer-bm">2.2.18. SQLTransformer (bm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#vectorassembler">2.2.19. VectorAssembler</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#quantilediscretizer">2.2.20. QuantileDiscretizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.et-fs.html#feature-selectors">2.3. Feature Selectors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#vectorslicer">2.3.1. VectorSlicer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#rformula">2.3.2. RFormula</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#chisqselector">2.3.3. ChiSqSelector</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.classification.html">3. Classification (<code class="docutils literal"><span class="pre">classification</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#logistic-regression">3.1. Logistic regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#decision-tree-classifier">3.2. Decision tree classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#random-forest-classifier">3.3. Random forest classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#gradient-boosted-tree-classifier">3.4. Gradient-boosted tree classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#multilayer-perceptron-classifier">3.5. Multilayer perceptron classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#one-vs-rest-classifier-a-k-a-one-vs-all">3.6. One-vs-Rest classifier (a.k.a. One-vs-All)</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#naive-bayes">3.7. Naive Bayes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.regression.html">4. Regression (<code class="docutils literal"><span class="pre">regression.rst</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#linear-regression">4.1. Linear regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#generalized-linear-regression">4.2. Generalized linear regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.regression.html#available-families">4.2.1. Available families</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#decision-tree-regression">4.3. Decision tree regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#random-forest-regression">4.4. Random forest regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#gradient-boosted-tree-regression">4.5. Gradient-boosted tree regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#survival-regression">4.6. Survival regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#isotonic-regression">4.7. Isotonic regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.regression.html#examples">4.7.1. Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.tree.html">5. Tree-based-methods (<code class="docutils literal"><span class="pre">tree.rst</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.tree.html#decision-trees">5.1. Decision trees</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.tree.html#inputs-and-outputs">5.1.1. Inputs and Outputs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.tree.html#tree-ensembles">5.2. Tree Ensembles</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.tree.html#random-forests">5.2.1. Random Forests</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.tree.html#gradient-boosted-trees-gbts">5.2.2. Gradient-Boosted Trees (GBTs)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apache-ml-rdd.html">MLLib: RDD-based API Guideline (<code class="docutils literal"><span class="pre">apache-ml-rdd</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-rdd.datatype.html">1. Data Types (<code class="docutils literal"><span class="pre">datatypes</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.datatype.html#local-vector">1.1. Local vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.datatype.html#labeled-point">1.2. Labeled point</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.datatype.html#local-matrix">1.3. Local matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.datatype.html#distributed-matrix">1.4. Distributed matrix</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.datatype.html#rowmatrix">1.4.1. RowMatrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.datatype.html#indexedrowmatrix">1.4.2. IndexedRowMatrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.datatype.html#coordinatematrix">1.4.3. CoordinateMatrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.datatype.html#blockmatrix">1.4.4. BlockMatrix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-rdd.stats.html">2. Basic Statistics (<code class="docutils literal"><span class="pre">stats</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#summary-statistics">2.1. Summary statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#correlations">2.2. Correlations</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#stratified-sampling">2.3. Stratified sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#hypothesis-testing">2.4. Hypothesis testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.stats.html#streaming-significance-testing">2.4.1. Streaming Significance Testing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#random-data-generation">2.5. Random data generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#kernel-density-estimation">2.6. Kernel density estimation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-rdd.eval.html">3. Evaluation metrics (<code class="docutils literal"><span class="pre">eval</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.eval.html#classification-model-evaluation">3.1. Classification model evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.eval.html#binary-classification">3.1.1. Binary classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.eval.html#multiclass-classification">3.1.2. Multiclass classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.eval.html#multilabel-classification">3.1.3. Multilabel classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.eval.html#ranking-systems">3.1.4. Ranking systems</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.eval.html#regression-model-evaluation">3.2. Regression model evaluation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Table of Contents (Others)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../top-sqlite.html">SQL notes (<code class="docutils literal"><span class="pre">top-sqlite.rst</span></code>)</a><ul class="simple">
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Coding Notebook</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
          <li><a href="apache-ml-guide.html">MLLib - Main guide (<code class="docutils literal"><span class="pre">apache-ml-guide.rst</span></code>)</a> &raquo;</li>
      
    <li>1. Pipeline-old (<code class="docutils literal"><span class="pre">pipeline-old</span></code>)</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/pyspark/apache-ml-guide.pipeline-old.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pipeline-old-pipeline-old">
<h1>1. Pipeline-old (<code class="docutils literal"><span class="pre">pipeline-old</span></code>)<a class="headerlink" href="#pipeline-old-pipeline-old" title="Permalink to this headline">¶</a></h1>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>Note taken from Spark 1.6.2 (now 2.0) from: <a class="reference external" href="https://spark.apache.org/docs/1.6.2/ml-guide.html">https://spark.apache.org/docs/1.6.2/ml-guide.html</a></p>
<p>Content nearly identical to <a class="reference external" href="http://spark.apache.org/docs/latest/ml-pipeline.html">http://spark.apache.org/docs/latest/ml-pipeline.html</a></p>
<p class="last"><strong>Timestamp</strong>: 09-08-2016 (15:33)</p>
</div>
<div class="contents local topic" id="contents">
<p class="topic-title first"><cite>Contents</cite></p>
<ul class="simple">
<li><a class="reference internal" href="#main-concepts-in-pipelines" id="id5">Main concepts in Pipelines</a></li>
<li><a class="reference internal" href="#dataframe" id="id6">DataFrame</a></li>
<li><a class="reference internal" href="#pipeline-components" id="id7">Pipeline components</a></li>
<li><a class="reference internal" href="#pipeline-transformers-and-estimators" id="id8">Pipeline (transformers and estimators)</a></li>
<li><a class="reference internal" href="#parameters" id="id9">Parameters</a></li>
<li><a class="reference internal" href="#saving-and-loading-pipelines" id="id10">Saving and Loading Pipelines</a></li>
<li><a class="reference internal" href="#code-examples" id="id11">Code Examples</a></li>
</ul>
</div>
<div class="section" id="main-concepts-in-pipelines">
<h2><a class="toc-backref" href="#id5">1.1. Main concepts in Pipelines</a><a class="headerlink" href="#main-concepts-in-pipelines" title="Permalink to this headline">¶</a></h2>
<p>Spark ML standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline, or workflow. This section covers the key concepts introduced by the Spark ML API, where the pipeline concept is mostly inspired by the scikit-learn project.</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">DataFrame</span></code>: Spark ML uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.</li>
<li><code class="docutils literal"><span class="pre">Transformer</span></code>: A Transformer is an algorithm which can <strong>transform one DataFrame into another DataFrame</strong>. E.g., an ML model is a Transformer which transforms DataFrame with features into a DataFrame with predictions.</li>
<li><code class="docutils literal"><span class="pre">Estimator</span></code>: An Estimator is an algorithm which can be <strong>fit on a DataFrame to produce a Transformer</strong>. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.</li>
<li><code class="docutils literal"><span class="pre">Pipeline</span></code>: A Pipeline <strong>chains multiple Transformers and Estimators</strong> together to specify an ML workflow.</li>
<li><code class="docutils literal"><span class="pre">Parameter</span></code>: All Transformers and Estimators now share a common API for specifying parameters.</li>
</ul>
</div>
<div class="section" id="dataframe">
<h2><a class="toc-backref" href="#id6">1.2. DataFrame</a><a class="headerlink" href="#dataframe" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Spark ML adopts the <code class="docutils literal"><span class="pre">DataFrame</span></code> from Spark SQL in order to support a variety of data types.</li>
<li>In addition to the types listed in the Spark SQL guide, DataFrame can use <code class="docutils literal"><span class="pre">ML</span> <span class="pre">Vector</span> <span class="pre">types</span></code>.</li>
<li>Columns in a DataFrame are named. The code examples below use names such as <code class="docutils literal"><span class="pre">“text,”</span> <span class="pre">“features,”</span> <span class="pre">and</span> <span class="pre">“label.”</span></code></li>
</ul>
</div>
<div class="section" id="pipeline-components">
<h2><a class="toc-backref" href="#id7">1.3. Pipeline components</a><a class="headerlink" href="#pipeline-components" title="Permalink to this headline">¶</a></h2>
<div class="section" id="transformers">
<h3>1.3.1. Transformers<a class="headerlink" href="#transformers" title="Permalink to this headline">¶</a></h3>
<div class="math">
\[\text{Transformer}(DataFrame)\rightarrow DataFrame\]</div>
<ul class="simple">
<li>A <code class="docutils literal"><span class="pre">Transformer</span></code> is an abstraction that includes feature transformers and learned models.</li>
<li>Technically, a Transformer implements a method <code class="docutils literal"><span class="pre">transform()</span></code>, which converts one DataFrame into another, generally by appending one or more columns.</li>
</ul>
<p>For example:</p>
<ul class="simple">
<li>A <strong>feature transformer</strong> might take a DataFrame, read a column (e.g., text), map it into a new column (e.g., feature vectors), and output a <strong>new DataFrame with the mapped column appended</strong>.</li>
<li>A <strong>learning model</strong> might take a DataFrame, read the column containing feature vectors, predict the label for each feature vector, and output a new DataFrame with <strong>predicted labels appended as a column</strong>.</li>
</ul>
</div>
<div class="section" id="estimators">
<h3>1.3.2. Estimators<a class="headerlink" href="#estimators" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>An <code class="docutils literal"><span class="pre">Estimator</span></code> abstracts the concept of a learning algorithm or any algorithm that fits or trains on data.</li>
<li>Technically, an Estimator implements a method <code class="docutils literal"><span class="pre">fit()</span></code>, which accepts a DataFrame and produces a <code class="docutils literal"><span class="pre">Model</span></code>, which is a <strong>Transformer</strong>.</li>
</ul>
<p>For example, a learning algorithm such as <code class="docutils literal"><span class="pre">LogisticRegression</span></code> is an <strong>Estimator</strong>, and calling <code class="docutils literal"><span class="pre">fit()</span></code> trains a <code class="docutils literal"><span class="pre">LogisticRegressionModel</span></code>, which is a <strong>Model</strong> and hence a <strong>Transformer</strong>.</p>
</div>
<div class="section" id="properties-of-pipeline-components">
<h3>1.3.3. Properties of pipeline components<a class="headerlink" href="#properties-of-pipeline-components" title="Permalink to this headline">¶</a></h3>
<p><a href="#id1"><span class="problematic" id="id2">``</span></a>Transformer.transform()``s and <a href="#id3"><span class="problematic" id="id4">``</span></a>Estimator.fit()``s are both <strong>stateless</strong>. In the future, stateful algorithms may be supported via alternative concepts.</p>
<p>Each instance of a Transformer or Estimator has a unique ID, which is useful in specifying parameters (discussed below).</p>
</div>
</div>
<div class="section" id="pipeline-transformers-and-estimators">
<h2><a class="toc-backref" href="#id8">1.4. Pipeline (transformers and estimators)</a><a class="headerlink" href="#pipeline-transformers-and-estimators" title="Permalink to this headline">¶</a></h2>
<div class="admonition-simple-text-document-processing-workflow admonition">
<p class="first admonition-title">simple text document processing workflow</p>
<p>Consider an example ML workflow:</p>
<ul class="last simple">
<li>Split each document’s text into words.</li>
<li>Convert each document’s words into a numerical feature vector.</li>
<li>Learn a prediction model using the feature vectors and labels.</li>
</ul>
</div>
<p>Spark ML represents such a workflow as a <code class="docutils literal"><span class="pre">Pipeline</span></code>, which consists of a sequence of <code class="docutils literal"><span class="pre">PipelineStages</span></code> <strong>(Transformers and Estimators)</strong> to be run in a specific order.</p>
<div class="section" id="how-it-works">
<h3>1.4.1. How it works<a class="headerlink" href="#how-it-works" title="Permalink to this headline">¶</a></h3>
<p>A <code class="docutils literal"><span class="pre">Pipeline</span></code> is specified as a sequence of <code class="docutils literal"><span class="pre">stages</span></code>, and each stage is either a <strong>Transformer</strong> or an <strong>Estimator</strong>.</p>
<ul class="simple">
<li>These stages are run in order, and the input DataFrame is transformed as it passes through each stage.</li>
<li>For <strong>Transformer</strong> stages, the <code class="docutils literal"><span class="pre">transform()</span></code> method is called on the DataFrame.</li>
<li>For <strong>Estimator stages</strong>, the <code class="docutils literal"><span class="pre">fit()</span></code> method is called to produce a <strong>Transformer</strong> (which becomes part of the <code class="docutils literal"><span class="pre">PipelineModel</span></code>, or <strong>fitted Pipeline</strong>), and that Transformer&#8217;s <code class="docutils literal"><span class="pre">transform()</span></code> method is called on the DataFrame.</li>
</ul>
<div class="admonition-training-time-usage-of-pipeline admonition">
<p class="first admonition-title">Training time usage of <code class="docutils literal"><span class="pre">Pipeline</span></code></p>
<p>The top row represents a <code class="docutils literal"><span class="pre">Pipeline</span></code> with <strong>three stages</strong>.</p>
<ul class="simple">
<li>The <strong>Tokenizer and HashingTF</strong> are <strong>Transformers (blue)</strong></li>
<li><code class="docutils literal"><span class="pre">LogisticRegression</span></code> is an <strong>Estimator (red)</strong>.</li>
</ul>
<p>The bottom row represents data flowing through the pipeline, where <strong>cylinders indicate DataFrames</strong>.</p>
<ul class="simple">
<li>The <code class="docutils literal"><span class="pre">Pipeline.fit()</span></code> method is called on the original DataFrame, which has raw text documents and labels.</li>
<li>The <code class="docutils literal"><span class="pre">Tokenizer.transform()</span></code> method splits the raw text documents into words, adding a new column with words to the DataFrame.</li>
<li>The <code class="docutils literal"><span class="pre">HashingTF.transform()</span></code> method converts the words column into feature vectors, adding a new column with those vectors to the DataFrame.</li>
<li>Since <code class="docutils literal"><span class="pre">LogisticRegression</span></code> is an <strong>Estimator</strong>, the Pipeline first calls <code class="docutils literal"><span class="pre">LogisticRegression.fit()</span></code> to produce a <code class="docutils literal"><span class="pre">LogisticRegressionModel</span></code>.</li>
<li>If the Pipeline had more stages, it would call the LogisticRegressionModel&#8217;s <code class="docutils literal"><span class="pre">transform()</span></code> method on the DataFrame before passing the DataFrame to the next stage.</li>
</ul>
<img alt="https://spark.apache.org/docs/1.6.2/img/ml-Pipeline.png" class="last align-center" src="https://spark.apache.org/docs/1.6.2/img/ml-Pipeline.png" />
</div>
<div class="admonition-test-time-usage-of-pipelinemodel admonition">
<p class="first admonition-title">Test time usage of <code class="docutils literal"><span class="pre">PipelineModel</span></code></p>
<p>A <strong>Pipeline is an Estimator</strong>. Thus, after a Pipeline&#8217;s fit() method runs, it produces a <code class="docutils literal"><span class="pre">PipelineModel</span></code>, which is a Transformer. This <code class="docutils literal"><span class="pre">PipelineModel</span></code> is used at <strong>test time</strong>; the figure below illustrates this usage.</p>
<p>In the figure below, the <code class="docutils literal"><span class="pre">PipelineModel</span></code> has the same number of stages as the original <code class="docutils literal"><span class="pre">Pipeline</span></code>, but <strong>all Estimators in the original Pipeline have become Transformers</strong>. When the PipelineModel&#8217;s <code class="docutils literal"><span class="pre">transform()</span></code> method is called on a test dataset, the data are passed through the fitted pipeline in order. Each stage&#8217;s <code class="docutils literal"><span class="pre">transform()</span></code> method updates the dataset and passes it to the next stage.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><code class="docutils literal"><span class="pre">Pipelines</span></code> and <code class="docutils literal"><span class="pre">PipelineModels</span></code> help to ensure that training and test data go through identical feature processing steps.</p>
</div>
<img alt="https://spark.apache.org/docs/1.6.2/img/ml-PipelineModel.png" class="last align-center" src="https://spark.apache.org/docs/1.6.2/img/ml-PipelineModel.png" />
</div>
</div>
<div class="section" id="details">
<h3>1.4.2. Details<a class="headerlink" href="#details" title="Permalink to this headline">¶</a></h3>
<p><strong>DAG Pipelines</strong>: A Pipeline’s stages are specified as an <strong>ordered array</strong>. The examples given here are all for <strong>linear Pipelines</strong>, i.e., Pipelines in which each stage uses data produced by the previous stage. It is possible to create <strong>non-linear Pipelines</strong> as long as the data flow graph forms a Directed Acyclic Graph (<strong>DAG</strong>). This graph is currently specified implicitly based on the input and output column names of each stage (generally specified as parameters). If the Pipeline forms a DAG, then the stages must be specified in <strong>topological order</strong>.</p>
<p><strong>Runtime checking</strong>: Since Pipelines can operate on DataFrames with varied types, they <em>cannot use compile-time type checking</em>. Pipelines and PipelineModels instead do <strong>runtime checking</strong> before actually running the Pipeline. This type checking is done using the DataFrame schema, a description of the data types of columns in the DataFrame.</p>
<p><strong>Unique Pipeline stages</strong>: A Pipeline’s stages should be unique instances. E.g., <em>the same instance myHashingTF should not be inserted into the Pipeline twice</em> since <em>Pipeline stages must have unique IDs</em>. However, different instances myHashingTF1 and myHashingTF2 (both of type <code class="docutils literal"><span class="pre">HashingTF</span></code>) can be put into the same Pipeline since <em>different instances will be created with different IDs</em>.</p>
</div>
</div>
<div class="section" id="parameters">
<h2><a class="toc-backref" href="#id9">1.5. Parameters</a><a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h2>
<p>Spark ML Estimators and Transformers use a uniform API for specifying parameters.</p>
<ul class="simple">
<li>A <code class="docutils literal"><span class="pre">Param</span></code> is a named parameter with self-contained documentation.</li>
<li>A <code class="docutils literal"><span class="pre">ParamMap</span></code> is a set of (parameter, value) pairs.</li>
</ul>
<p>There are two main ways to pass parameters to an algorithm:</p>
<ul class="simple">
<li>Set parameters for an instance.<ul>
<li>E.g., if <code class="docutils literal"><span class="pre">lr</span></code> is an instance of <code class="docutils literal"><span class="pre">LogisticRegression</span></code>, one could call <code class="docutils literal"><span class="pre">lr.setMaxIter(10)</span></code> to make <code class="docutils literal"><span class="pre">lr.fit()</span></code> use at most 10 iterations.</li>
<li>This API resembles the API used in <code class="docutils literal"><span class="pre">spark.mllib</span> <span class="pre">package</span></code>.</li>
</ul>
</li>
<li>Pass a <code class="docutils literal"><span class="pre">ParamMap</span></code> to <code class="docutils literal"><span class="pre">fit()</span></code> or <code class="docutils literal"><span class="pre">transform()</span></code>.<ul>
<li>Any parameters in the ParamMap will override parameters previously specified via setter methods.</li>
</ul>
</li>
</ul>
<p>Parameters belong to specific instances of Estimators and Transformers.</p>
<ul class="simple">
<li>For example, suppose we have two <strong>LogisticRegression</strong> instances <code class="docutils literal"><span class="pre">lr1</span></code> and <code class="docutils literal"><span class="pre">lr2</span></code></li>
<li>we can build a <em>ParamMap</em> with both <em>maxIter</em> parameters specified: <code class="docutils literal"><span class="pre">ParamMap(lr1.maxIter</span> <span class="pre">-&gt;</span> <span class="pre">10,</span> <span class="pre">lr2.maxIter</span> <span class="pre">-&gt;</span> <span class="pre">20)</span></code>.</li>
<li>This is useful if there are two algorithms with the <em>maxIter</em> parameter in a <em>Pipeline</em>.</li>
</ul>
</div>
<div class="section" id="saving-and-loading-pipelines">
<h2><a class="toc-backref" href="#id10">1.6. Saving and Loading Pipelines</a><a class="headerlink" href="#saving-and-loading-pipelines" title="Permalink to this headline">¶</a></h2>
<p>Often times it is worth it to save a model or a pipeline to disk for later use. In Spark 1.6, a model import/export functionality was added to the Pipeline API. Most basic transformers are supported as well as some of the more basic ML models. Please refer to the algorithm’s API documentation to see if saving and loading is supported.</p>
</div>
<div class="section" id="code-examples">
<h2><a class="toc-backref" href="#id11">1.7. Code Examples</a><a class="headerlink" href="#code-examples" title="Permalink to this headline">¶</a></h2>
<div class="section" id="estimator-transformer-and-param">
<h3>1.7.1. Estimator, Transformer, and Param<a class="headerlink" href="#estimator-transformer-and-param" title="Permalink to this headline">¶</a></h3>
<p>This example covers the concepts of Estimator, Transformer, and Param.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.mllib.linalg</span> <span class="kn">import</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.classification</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.param</span> <span class="kn">import</span> <span class="n">Param</span><span class="p">,</span> <span class="n">Params</span>

<span class="c1"># Prepare training data from a list of (label, features) tuples.</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])),</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">]))],</span> <span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="c1"># Create a LogisticRegression instance. This instance is an Estimator.</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">maxIter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">regParam</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="c1"># Print out the parameters, documentation, and any default values.</span>
<span class="k">print</span> <span class="s2">&quot;LogisticRegression parameters:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">lr</span><span class="o">.</span><span class="n">explainParams</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

<span class="c1"># Learn a LogisticRegression model. This uses the parameters stored in lr.</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>

<span class="c1"># Since model1 is a Model (i.e., a transformer produced by an Estimator),</span>
<span class="c1"># we can view the parameters it used during fit().</span>
<span class="c1"># This prints the parameter (name: value) pairs, where names are unique IDs for this</span>
<span class="c1"># LogisticRegression instance.</span>
<span class="k">print</span> <span class="s2">&quot;Model 1 was fit using parameters: &quot;</span>
<span class="k">print</span> <span class="n">model1</span><span class="o">.</span><span class="n">extractParamMap</span><span class="p">()</span>

<span class="c1"># We may alternatively specify parameters using a Python dictionary as a paramMap</span>
<span class="n">paramMap</span> <span class="o">=</span> <span class="p">{</span><span class="n">lr</span><span class="o">.</span><span class="n">maxIter</span><span class="p">:</span> <span class="mi">20</span><span class="p">}</span>
<span class="n">paramMap</span><span class="p">[</span><span class="n">lr</span><span class="o">.</span><span class="n">maxIter</span><span class="p">]</span> <span class="o">=</span> <span class="mi">30</span> <span class="c1"># Specify 1 Param, overwriting the original maxIter.</span>
<span class="n">paramMap</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">lr</span><span class="o">.</span><span class="n">regParam</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span> <span class="mf">0.55</span><span class="p">})</span> <span class="c1"># Specify multiple Params.</span>

<span class="c1"># You can combine paramMaps, which are python dictionaries.</span>
<span class="n">paramMap2</span> <span class="o">=</span> <span class="p">{</span><span class="n">lr</span><span class="o">.</span><span class="n">probabilityCol</span><span class="p">:</span> <span class="s2">&quot;myProbability&quot;</span><span class="p">}</span> <span class="c1"># Change output column name</span>
<span class="n">paramMapCombined</span> <span class="o">=</span> <span class="n">paramMap</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">paramMapCombined</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">paramMap2</span><span class="p">)</span>

<span class="c1"># Now learn a new model using the paramMapCombined parameters.</span>
<span class="c1"># paramMapCombined overrides all parameters set earlier via lr.set* methods.</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">paramMapCombined</span><span class="p">)</span>
<span class="k">print</span> <span class="s2">&quot;Model 2 was fit using parameters: &quot;</span>
<span class="k">print</span> <span class="n">model2</span><span class="o">.</span><span class="n">extractParamMap</span><span class="p">()</span>

<span class="c1"># Prepare test data</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">])),</span>
    <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])),</span>
    <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">Vectors</span><span class="o">.</span><span class="n">dense</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">]))],</span> <span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">])</span>

<span class="c1"># Make predictions on test data using the Transformer.transform() method.</span>
<span class="c1"># LogisticRegression.transform will only use the &#39;features&#39; column.</span>
<span class="c1"># Note that model2.transform() outputs a &quot;myProbability&quot; column instead of the usual</span>
<span class="c1"># &#39;probability&#39; column since we renamed the lr.probabilityCol parameter previously.</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">selected</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;myProbability&quot;</span><span class="p">,</span> <span class="s2">&quot;prediction&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">selected</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
    <span class="k">print</span> <span class="n">row</span>
</pre></div>
</div>
</div>
<div class="section" id="example-pipeline">
<h3>1.7.2. Example: Pipeline<a class="headerlink" href="#example-pipeline" title="Permalink to this headline">¶</a></h3>
<p>This example follows the simple text document Pipeline illustrated in the figures below.</p>
<img alt="https://spark.apache.org/docs/1.6.2/img/ml-Pipeline.png" class="align-center" src="https://spark.apache.org/docs/1.6.2/img/ml-Pipeline.png" />
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.classification</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">HashingTF</span><span class="p">,</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span>

<span class="c1"># Prepare training documents from a list of (id, text, label) tuples.</span>
<span class="n">LabeledDocument</span> <span class="o">=</span> <span class="n">Row</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">)</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="il">0L</span><span class="p">,</span> <span class="s2">&quot;a b c d e spark&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="il">1L</span><span class="p">,</span> <span class="s2">&quot;b d&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
    <span class="p">(</span><span class="il">2L</span><span class="p">,</span> <span class="s2">&quot;spark f g h&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="il">3L</span><span class="p">,</span> <span class="s2">&quot;hadoop mapreduce&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">])</span>

<span class="c1"># Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">)</span>
<span class="n">hashingTF</span> <span class="o">=</span> <span class="n">HashingTF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">(),</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">maxIter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">regParam</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">hashingTF</span><span class="p">,</span> <span class="n">lr</span><span class="p">])</span>

<span class="c1"># Fit the pipeline to training documents.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>

<span class="c1"># Prepare test documents, which are unlabeled (id, text) tuples.</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="il">4L</span><span class="p">,</span> <span class="s2">&quot;spark i j k&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="il">5L</span><span class="p">,</span> <span class="s2">&quot;l m n&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="il">6L</span><span class="p">,</span> <span class="s2">&quot;mapreduce spark&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="il">7L</span><span class="p">,</span> <span class="s2">&quot;apache hadoop&quot;</span><span class="p">)],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">])</span>

<span class="c1"># Make predictions on test documents and print columns of interest.</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">selected</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;prediction&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">selected</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="example-model-selection-via-cv-scala">
<h3>1.7.3. Example: model selection via CV (Scala)<a class="headerlink" href="#example-model-selection-via-cv-scala" title="Permalink to this headline">¶</a></h3>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.classification.LogisticRegression</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.evaluation.BinaryClassificationEvaluator</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.feature.</span><span class="o">{</span><span class="nc">HashingTF</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.tuning.</span><span class="o">{</span><span class="nc">ParamGridBuilder</span><span class="o">,</span> <span class="nc">CrossValidator</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.mllib.linalg.Vector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.Row</span>

<span class="c1">// Prepare training data from a list of (id, text, label) tuples.</span>
<span class="k">val</span> <span class="n">training</span> <span class="k">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0L</span><span class="o">,</span> <span class="s">&quot;a b c d e spark&quot;</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">1L</span><span class="o">,</span> <span class="s">&quot;b d&quot;</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">2L</span><span class="o">,</span> <span class="s">&quot;spark f g h&quot;</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">3L</span><span class="o">,</span> <span class="s">&quot;hadoop mapreduce&quot;</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">4L</span><span class="o">,</span> <span class="s">&quot;b spark who&quot;</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">5L</span><span class="o">,</span> <span class="s">&quot;g d a y&quot;</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">6L</span><span class="o">,</span> <span class="s">&quot;spark fly&quot;</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">7L</span><span class="o">,</span> <span class="s">&quot;was mapreduce&quot;</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">8L</span><span class="o">,</span> <span class="s">&quot;e spark program&quot;</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">9L</span><span class="o">,</span> <span class="s">&quot;a e c l&quot;</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">10L</span><span class="o">,</span> <span class="s">&quot;spark compile&quot;</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">11L</span><span class="o">,</span> <span class="s">&quot;hadoop software&quot;</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;text&quot;</span><span class="o">,</span> <span class="s">&quot;label&quot;</span><span class="o">)</span>

<span class="c1">// Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.</span>
<span class="k">val</span> <span class="n">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="s">&quot;text&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;words&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">hashingTF</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">HashingTF</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setInputCol</span><span class="o">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setOutputCol</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">lr</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">LogisticRegression</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setMaxIter</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
<span class="k">val</span> <span class="n">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">tokenizer</span><span class="o">,</span> <span class="n">hashingTF</span><span class="o">,</span> <span class="n">lr</span><span class="o">))</span>

<span class="c1">// We use a ParamGridBuilder to construct a grid of parameters to search over.</span>
<span class="c1">// With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,</span>
<span class="c1">// this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.</span>
<span class="k">val</span> <span class="n">paramGrid</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ParamGridBuilder</span><span class="o">()</span>
  <span class="o">.</span><span class="n">addGrid</span><span class="o">(</span><span class="n">hashingTF</span><span class="o">.</span><span class="n">numFeatures</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span> <span class="mi">100</span><span class="o">,</span> <span class="mi">1000</span><span class="o">))</span>
  <span class="o">.</span><span class="n">addGrid</span><span class="o">(</span><span class="n">lr</span><span class="o">.</span><span class="n">regParam</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.01</span><span class="o">))</span>
  <span class="o">.</span><span class="n">build</span><span class="o">()</span>

<span class="c1">// We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.</span>
<span class="c1">// This will allow us to jointly choose parameters for all Pipeline stages.</span>
<span class="c1">// A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.</span>
<span class="c1">// Note that the evaluator here is a BinaryClassificationEvaluator and its default metric</span>
<span class="c1">// is areaUnderROC.</span>
<span class="k">val</span> <span class="n">cv</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CrossValidator</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setEstimator</span><span class="o">(</span><span class="n">pipeline</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setEvaluator</span><span class="o">(</span><span class="k">new</span> <span class="nc">BinaryClassificationEvaluator</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setEstimatorParamMaps</span><span class="o">(</span><span class="n">paramGrid</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setNumFolds</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="c1">// Use 3+ in practice</span>

<span class="c1">// Run cross-validation, and choose the best set of parameters.</span>
<span class="k">val</span> <span class="n">cvModel</span> <span class="k">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">training</span><span class="o">)</span>

<span class="c1">// Prepare test documents, which are unlabeled (id, text) tuples.</span>
<span class="k">val</span> <span class="n">test</span> <span class="k">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">4L</span><span class="o">,</span> <span class="s">&quot;spark i j k&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">5L</span><span class="o">,</span> <span class="s">&quot;l m n&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">6L</span><span class="o">,</span> <span class="s">&quot;mapreduce spark&quot;</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">7L</span><span class="o">,</span> <span class="s">&quot;apache hadoop&quot;</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;text&quot;</span><span class="o">)</span>

<span class="c1">// Make predictions on test documents. cvModel uses the best model found (lrModel).</span>
<span class="n">cvModel</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">test</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;text&quot;</span><span class="o">,</span> <span class="s">&quot;probability&quot;</span><span class="o">,</span> <span class="s">&quot;prediction&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">collect</span><span class="o">()</span>
  <span class="o">.</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">case</span> <span class="nc">Row</span><span class="o">(</span><span class="n">id</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">text</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">prob</span><span class="k">:</span> <span class="kt">Vector</span><span class="o">,</span> <span class="n">prediction</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span> <span class="k">=&gt;</span>
    <span class="n">println</span><span class="o">(</span><span class="s">s&quot;(</span><span class="si">$id</span><span class="s">, </span><span class="si">$text</span><span class="s">) --&gt; prob=</span><span class="si">$prob</span><span class="s">, prediction=</span><span class="si">$prediction</span><span class="s">&quot;</span><span class="o">)</span>
  <span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="example-model-selection-via-train-validation-split-scala">
<h3>1.7.4. Example: model selection via train validation split (scala)<a class="headerlink" href="#example-model-selection-via-train-validation-split-scala" title="Permalink to this headline">¶</a></h3>
<div class="highlight-scala"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.evaluation.RegressionEvaluator</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.regression.LinearRegression</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.tuning.</span><span class="o">{</span><span class="nc">ParamGridBuilder</span><span class="o">,</span> <span class="nc">TrainValidationSplit</span><span class="o">}</span>

<span class="c1">// Prepare training and test data.</span>
<span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_linear_regression_data.txt&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="nc">Array</span><span class="o">(</span><span class="n">training</span><span class="o">,</span> <span class="n">test</span><span class="o">)</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">randomSplit</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mf">0.9</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">),</span> <span class="n">seed</span> <span class="k">=</span> <span class="mi">12345</span><span class="o">)</span>

<span class="k">val</span> <span class="n">lr</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">LinearRegression</span><span class="o">()</span>

<span class="c1">// We use a ParamGridBuilder to construct a grid of parameters to search over.</span>
<span class="c1">// TrainValidationSplit will try all combinations of values and determine best model using</span>
<span class="c1">// the evaluator.</span>
<span class="k">val</span> <span class="n">paramGrid</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ParamGridBuilder</span><span class="o">()</span>
  <span class="o">.</span><span class="n">addGrid</span><span class="o">(</span><span class="n">lr</span><span class="o">.</span><span class="n">regParam</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mf">0.1</span><span class="o">,</span> <span class="mf">0.01</span><span class="o">))</span>
  <span class="o">.</span><span class="n">addGrid</span><span class="o">(</span><span class="n">lr</span><span class="o">.</span><span class="n">fitIntercept</span><span class="o">)</span>
  <span class="o">.</span><span class="n">addGrid</span><span class="o">(</span><span class="n">lr</span><span class="o">.</span><span class="n">elasticNetParam</span><span class="o">,</span> <span class="nc">Array</span><span class="o">(</span><span class="mf">0.0</span><span class="o">,</span> <span class="mf">0.5</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">))</span>
  <span class="o">.</span><span class="n">build</span><span class="o">()</span>

<span class="c1">// In this case the estimator is simply the linear regression.</span>
<span class="c1">// A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.</span>
<span class="k">val</span> <span class="n">trainValidationSplit</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TrainValidationSplit</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setEstimator</span><span class="o">(</span><span class="n">lr</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setEvaluator</span><span class="o">(</span><span class="k">new</span> <span class="nc">RegressionEvaluator</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setEstimatorParamMaps</span><span class="o">(</span><span class="n">paramGrid</span><span class="o">)</span>
  <span class="c1">// 80% of the data will be used for training and the remaining 20% for validation.</span>
  <span class="o">.</span><span class="n">setTrainRatio</span><span class="o">(</span><span class="mf">0.8</span><span class="o">)</span>

<span class="c1">// Run train validation split, and choose the best set of parameters.</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">trainValidationSplit</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">training</span><span class="o">)</span>

<span class="c1">// Make predictions on test data. model is the model with combination of parameters</span>
<span class="c1">// that performed best.</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">test</span><span class="o">)</span>
  <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;features&quot;</span><span class="o">,</span> <span class="s">&quot;label&quot;</span><span class="o">,</span> <span class="s">&quot;prediction&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="apache-ml-guide.et-fs.html" class="btn btn-neutral float-right" title="2. Extracting, transforming and selecting features (et-fs)" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="apache-ml-guide.html" class="btn btn-neutral" title="MLLib - Main guide (apache-ml-guide.rst)" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Takanori Watanabe.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>