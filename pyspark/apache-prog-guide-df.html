

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>4 Spark Programming Guide DataFrames (apache-prog-guide-df)</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon-umich.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/my_theme.css" type="text/css" />
  

  

  
    <link rel="top" title="" href="../index.html"/>
        <link rel="up" title="PySpark Notes (top-pyspark.rst)" href="top-pyspark.html"/>
        <link rel="next" title="5 Databrick Doc (databricks.rst)" href="databricks.html"/>
        <link rel="prev" title="3 pyspark-overflow.rst" href="pyspark-overflow.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Coding Notebook
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Table of Contents (PySpark)</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="top-edx.html">EdX - Data Science and Engineering with Spark</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab0.html">cs105_lab0 - Running Your First Notebook</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab0.html#create-dataframe-and-filter-it">Create DataFrame and filter it</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab0.html#load-a-text-file">Load a text file</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab0.html#check-plotting">Check plotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab1a.html">cs105_lab1a - Learning Apache Spark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a.html#spark-context">Spark Context</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a.html#sparkcontext-and-the-driver-program-cluster-structure">SparkContext and the Driver Program (Cluster Structure)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#about-the-driver-program">About the Driver Program</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#about-hivecontext-the-type-of-sqlcontext-for-db">About HiveContext (the type of sqlContext for DB)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#sparkcontext">SparkContext</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a.html#using-dataframes-and-chaining-transformations">Using DataFrames and chaining transformations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#dataframe-and-schema">DataFrame and Schema</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#ways-to-define-schemas">Ways to define schemas</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#distributed-data-and-using-a-collection-to-create-a-dataframe">Distributed Data and using a collection to create a DataFrame</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a.html#query-plans-and-the-catalyst-optimizer">Query plans and the <code class="docutils literal"><span class="pre">Catalyst</span> <span class="pre">Optimizer</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab1a_coding.html">cs105_lab1a codes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#exercise-overview">Exercise Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#create-list-of-data">Create list of Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#create-dataframe-from-a-list">Create DataFrame from a list</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#subtract-one-from-each-the-age-row">Subtract one from each the <em>age</em> row</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#apply-transformations-and-examine-query-plan">Apply transformations, and examine query plan</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#use-collect-to-view-results">Use <code class="docutils literal"><span class="pre">collect</span></code> to view results</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#display-helper-function-in-db">display helper function in DB</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#more-actions-count-to-get-total">More actions: <code class="docutils literal"><span class="pre">count</span></code> to get total</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#apply-transformation-filter-and-view-results-with-collect">Apply transformation <code class="docutils literal"><span class="pre">filter</span></code> and view results with <code class="docutils literal"><span class="pre">collect</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#lambda-functions-and-udfs">Lambda functions and UDFs</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#additional-dataframe-actions">Additional DataFrame actions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#additional-dataframe-transformations">Additional DataFrame transformations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#orderby">orderBy</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#a-distinct-and-dropduplicates">A <code class="docutils literal"><span class="pre">distinct</span></code> and <code class="docutils literal"><span class="pre">dropDuplicates</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#drop">drop</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#groupby">groupBy</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#sample">sample</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#caching-dataframes-and-storage-options">Caching DataFrames and Storage Options</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#unpersist-and-storage-options">Unpersist and storage options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1a_coding.html#debugging-spark-applications-and-lazy-evaluation">Debugging Spark applications and lazy evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#jvm-and-py4j-how-python-is-executed-in-spark">JVM and Py4J - How Python is Executed in Spark</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#challenges-with-lazy-evaluation-using-transformations-and-actions">Challenges with lazy evaluation using transformations and actions</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#finding-the-bug">Finding the bug</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1a_coding.html#moving-toward-expert-style">Moving toward expert style</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab1b.html">cs105_lab1b - Building a word count application</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#create-a-base-df-and-perform-operations">Create a base DF and perform operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#create-a-base-df">Create a base DF</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#use-df-functions-to-add-an-s">Use DF functions to add an &#8216;s&#8217;</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#length-of-each-word">Length of each word</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#counting-with-spark-sql-and-dataframes">Counting with Spark SQL and DataFrames</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#using-groupby-and-count">Using groupBy and count</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#finding-unique-words-and-a-mean-value">Finding unique words and a mean value</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#unique-words">Unique words</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#means-of-groups-using-dataframes">Means of groups using DataFrames</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#apply-word-count-to-a-file">Apply word count to a file</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#the-wordcount-function">The wordCount function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#capitalization-and-punctuation">Capitalization and punctuation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#load-a-text-file">Load a text file</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#words-from-lines">Words from lines</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab1b.html#count-the-words">Count the words</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab1b.html#random-stuffs-i-played-around-with">Random stuffs I played around with</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs105_lab2.html">cs105_lab2 - Web Server Log Analysis with Apache Spark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#part1-overview-web-server-log-analysis-with-apache-spark">Part1: Overview: Web Server Log Analysis with Apache Spark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#modules-used-in-this-assignment">Modules used in this assignment</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#dataset-used">Dataset used</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#part2-exploratory-data-analysis">Part2: Exploratory Data Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#a-loading-the-log-file">2a) loading the log file</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#b-parsing-the-log-file">2b) Parsing the log file</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#c-data-cleaning">2c) Data Cleaning</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#fix-the-rows-with-null-content-size">Fix the rows with null content_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#parsing-the-timestamp">Parsing the timestamp</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#part3-analysis-walk-through-on-the-web-server-log-file">Part3: Analysis Walk-Through on the Web Server Log File</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#a-example-content-size-statistics">3a) Example: Content Size Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#b-example-http-status-analysis">3b) Example: HTTP Status Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#c-example-status-graphing">3c) Example: Status Graphing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#d-example-frequent-hosts">3d) Example: Frequent Hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#e-example-visualizing-paths">3e) Example: Visualizing Paths</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#f-example-top-paths">3f) Example: Top Paths</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs105_lab2.html#part-4-analyzing-web-server-log-file">Part 4: Analyzing Web Server Log File</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#a-exercise-top-ten-error-paths-hw">4a) Exercise: Top Ten Error Paths (HW)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#b-exercise-number-of-unique-hosts-hw">4b) Exercise: Number of Unique Hosts (HW)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#c-exercise-number-of-unique-daily-hosts">4c) Exercise: Number of Unique Daily Hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#d-exercise-visualizing-the-number-of-unique-daily-hosts">4d) Exercise: Visualizing the Number of Unique Daily Hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#e-exercise-average-number-of-daily-requests-per-host">4e) Exercise: Average Number of Daily Requests per Host</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs105_lab2.html#f-exercise-visualizing-the-average-daily-requests-per-unique-host">4f) Exercise: Visualizing the Average Daily Requests per Unique Host</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs110_lab1.html">cs110 - Power Plant Machine Learning Pipeline Application</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#part1-business-understanding">Part1: Business Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#background-power-generation">Background &#8212; power generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#challenge-for-power-grid-operation">Challenge for power grid operation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#the-business-problem">The business problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#business-understanding">Business Understanding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#part2-extract-transform-load-etl-your-data">Part2: Extract-Transform-Load (ETL) Your Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-2a">Exercise 2a</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-2b">Exercise 2b</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#part-2-alternative-method-to-load-your-data">Part 2: Alternative Method to Load your Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-2c">Exercise 2c</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-2d">Exercise 2d</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#part-3-explore-your-data">Part 3: Explore Your Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#a-register-the-dataframe-to-use-sql-commands">3a - <strong>register</strong> the DataFrame (to use sql commands)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#b-read-data-using-sql-command-databricks-only">3b - read data using <code class="docutils literal"><span class="pre">%sql</span></code> command (DataBricks only)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#c-use-sql-desc-command-to-describe-the-schema">3c - use SQL <code class="docutils literal"><span class="pre">desc</span></code> command to describe the schema</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#dataframe-describe-method">DataFrame <code class="docutils literal"><span class="pre">describe</span></code> method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#part-4-visualize-your-data">Part 4: Visualize your data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-4a">Exercise 4a</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-4b-hw">Exercise 4b (hw)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-4c-hw">Exercise 4c (hw)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-4d-hw">Exercise 4d (hw)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#part-5-data-preparation">Part 5: Data Preparation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-5-a">Exercise 5(a)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#part-6-data-modeling">Part 6: Data Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-6-a-hw">Exercise 6(a) (hw)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#b-build-linear-regression-model">6(b) - build Linear Regression Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#c-set-model-parameters-and-fit-linear-regression-model">6(c) - set model parameters, and fit linear regression model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#d-study-the-fitted-lr-model">6(d) &#8212; study the fitted LR model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#e-evalute-model-on-the-20-test-set">6(e) evalute model on the 20% test-set</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#f-quantify-performance-using-regressionevaluator">6(f) &#8211; quantify performance using <code class="docutils literal"><span class="pre">RegressionEvaluator</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#g-use-r2-this-time">6(g) use R2 this time</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#h-register-our-test-dataframe-as-sql-table">6(h) Register our test DataFrame as SQL table</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#i-sql-statement-on-the-sql-table-registered-from-our-test-dataframe">6(i) SQL statement on the SQL table registered from our test DataFrame</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#j-plot-histogram-of-rmse">6(j) Plot histogram of RMSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#k-plot-pie-chart">6(k) Plot pie chart</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab1.html#part-7-tuning-and-evaluation">Part 7: Tuning and Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#a-run-cross-validation-tuning">7(a) Run Cross Validation Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-b-evaluate-tuned-lr-model-hw">Exercise 7(b) &#8211; Evaluate tuned LR model (hw)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-c-decisiontreeregressor">Exercise 7(c) DecisionTreeRegressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-d">Exercise 7(d)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-e-evaluate-dtr-performance">Exercise 7(e) &#8212; evaluate DTR performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-f-random-forest-regressor">Exercise 7(f) (Random Forest Regressor)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-g-cross-validation">Exercise 7(g) (cross validation)</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab1.html#exercise-7-h-model-evaluation">Exercise 7(h) (model evaluation)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs110_lab2.html">cs110 - Predicting Movie Ratings with Alternating Least Squares</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab2.html#preliminaries">Preliminaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#the-20-million-movie-sample">The 20-million movie sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#cpu-vs-io-tradeoff">CPU vs IO Tradeoff</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#load-and-cache">Load and Cache</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab2.html#basic-recommendations">Basic Recommendations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-1a-movies-with-highest-average-ratings">Exercise (1a) Movies with Highest Average Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-1b-movies-with-highest-average-ratings-and-at-least-500-reviews">Exercise (1b) Movies with Highest Average Ratings and at least 500 reviews</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab2.html#collaborative-filtering">Collaborative Filtering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-2a-creating-a-training-set">Exercise (2a) Creating a Training Set</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-2b-alternating-least-squares">Exercise (2b) Alternating Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#why-are-we-doing-our-own-cross-validation">Why are we doing our own cross-validation?</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#excersie-2c-testing-your-model">Excersie (2c) Testing Your Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-2d-comparing-your-model">Exercise (2d) Comparing Your Model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab2.html#predictions-for-yourself">Predictions for Yourself</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3a-your-movie-ratings">Exercise (3a) Your Movie Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3b-add-your-movies-to-training-dataset">Exercise (3b) Add Your Movies to Training Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3c-train-a-model-with-your-ratings">Exercise (3c) Train a Model with Your Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3d-check-rmse-for-the-new-model-with-your-ratings">Exercise (3d) Check RMSE for the New Model with Your Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3e-predict-your-ratings">Exercise (3e) Predict Your Ratings</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab2.html#exercise-3f-predict-your-ratings">Exercise (3f) Predict Your Ratings</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs110_lab3b.html">cs110 - Text Analysis and Entity Resolution with TF-IDF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#preliminaries">Preliminaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#background-on-er">Background on ER</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#data-files">Data files</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#load-data-files">Load data files</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#examine-the-lines-loaded">Examine the lines loaded</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#part1-er-as-text-similarity-bags-of-words">Part1: ER as Text Similarity - Bags of Words</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#a-tokenize-a-string">1a) Tokenize a String</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#b-removing-stopwords">1b) removing stopwords</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#c-tokenizing-the-small-datasets">1c) Tokenizing the small datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#d-amazon-record-with-the-most-tokens">1d) Amazon record with the most tokens</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#part2-er-as-text-similarity-weighted-bag-of-words-using-tf-idf">Part2: ER as Text Similarity - Weighted Bag-of-Words using TF-IDF</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#a-implement-a-tf-function">2a) Implement a TF function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#b-create-a-corpus">2b) Create a corpus</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#c-implement-an-idfs-function">2c) Implement an IDFs function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#d-tokens-with-the-smallest-idf">2d) Tokens with the smallest IDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#e-idf-histogram">2e) IDF Histogram</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#f-implement-a-tf-idf-function">2f) Implement a TF-IDF function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#part-3-er-as-text-similarity-cosine-similarity">Part 3: ER as Text Similarity &#8212; Cosine Similarity</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#a-implement-the-components-of-a-cosinesimilarity-function">3a) Implement the components of a cosineSimilarity function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#b-implement-a-cosinesimilarity-function">3b) Implement a cosineSimilarity function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#c-perform-entity-resolution">3c) Perform Entity Resolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#d-perform-entity-resolution-with-broadcast-variables">3d) Perform Entity Resolution with Broadcast Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#e-perform-a-gold-standard-evaluation">3e) Perform a Gold Standard evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#using-the-gold-standard-data-we-can-answer-the-following-questions">Using the &#8220;gold standard&#8221; data we can answer the following questions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#part-4-scalable-er">Part 4: Scalable ER</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#inverted-indices">Inverted Indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#a-tokenize-the-full-dataset">4a) Tokenize the full dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#b-compute-idfs-and-tf-idfs-for-the-full-datasets">4b) Compute IDFs and TF-IDFs for the full datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#c-compute-norms-for-the-weights-from-the-full-datasets">4c) Compute Norms for the weights from the full datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#d-create-inverted-indices-from-the-full-datasets">4d) Create inverted indices from the full datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#e-identify-common-tokens-from-the-full-dataset">4e) Identify common tokens from the full dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#f-identify-common-tokens-from-the-full-dataset">4f) Identify common tokens from the full dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#part-5-analysis">Part 5: Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#a-counting-true-positives-false-positives-and-false-negatives">5a) Counting True Positives, False Positives, and False Negatives</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#b-precision-recall-and-f-measures">5b Precision, Recall, and F-measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs110_lab3b.html#c-line-plots">5c Line Plots</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs110_lab3b.html#discussion-of-results">Discussion of results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab1a.html">cs120 Lab - Math_review</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1a.html#math-review">Math review</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-1a-scalar-multiplication-vectors">Exercise (1a) Scalar multiplication: vectors</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-1b-element-wise-multiplication-vectors">Exercise (1b) Element-wise multiplication: vectors</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-1c-dot-product">Exercise (1c) Dot product</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-1d-matrix-multiplication">Exercise (1d) Matrix multiplication</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1a.html#numpy">NumPy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-2a-scalar-multiplication">Exercise (2a) Scalar multiplication</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-2b-element-wise-multiplication-and-dot-product">Exercise (2b) Element-wise multiplication and dot product</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-2c-matrix-math">Exercise (2c) Matrix math</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1a.html#additional-numpy-and-spark-linear-algebra">Additional NumPy and Spark linear algebra</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-3a-slices">Exercise (3a) Slices</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-3b-combining-ndarray-objects">Exercise (3b) Combining ndarray objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-3c-pyspark-s-densevector">Exercise (3c) PySpark&#8217;s DenseVector</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1a.html#python-lambda-expressions">Python lambda expressions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4a-lambda-is-an-anonymous-function">Exercise (4a) Lambda is an anonymous function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4b-lambda-fewer-steps-than-def">Exercise (4b) lambda fewer steps than def</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4c-lambda-expression-arguments">Exercise (4c) Lambda expression arguments</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4d-restrictions-on-lambda-expressions">Exercise (4d) Restrictions on lambda expressions</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4e-functional-programming">Exercise (4e) Functional programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1a.html#exercise-4f-composability">Exercise (4f) Composability</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab1b.html">cs120 - Word Count Lab in RDD</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1b.html#part-1-creating-a-base-rdd-and-pair-rdds">Part 1: Creating a base RDD and pair RDDs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#b-pluralize-and-test">1b) Pluralize and test</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#c-apply-makeplural-to-the-base-rdd">1c) Apply makePlural to the base RDD</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#d-pass-a-lambda-function-to-map">1d) Pass a lambda function to map</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#e-length-of-each-word">1e) Length of each word</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#f-pair-rdds">1f) Pair RDDs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1b.html#part-2-counting-with-pair-rdds">Part 2: Counting with pair RDDs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#a-groupbykey-approach">2a) <code class="docutils literal"><span class="pre">groupByKey()</span></code> approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#b-use-groupbykey-to-obtain-the-counts">2b) Use <code class="docutils literal"><span class="pre">groupByKey()</span></code> to obtain the counts</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#c-counting-using-reducebykey">2c) Counting using <code class="docutils literal"><span class="pre">reduceByKey</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#d-all-together">2d) All together</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1b.html#part-3-finding-unique-words-and-a-mean-value">Part 3: Finding unique words and a mean value</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#a-unique-words">3a) Unique words</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#b-mean-using-reduce">3b) Mean using <code class="docutils literal"><span class="pre">reduce</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab1b.html#part-4-apply-word-count-to-a-file">Part 4: Apply word count to a file</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#a-wordcount-function">4a) <code class="docutils literal"><span class="pre">wordCount</span></code> function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#b-capitalization-and-punctuation">4b) Capitalization and punctuation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#c-load-a-text-file">4c) Load a text file</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#d-words-from-lines">4d) Words from lines</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#e-remove-empty-elements">4e) Remove empty elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab1b.html#f-count-the-words">4f) Count the words</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab2.html">cs120 - Linear Regression with DataFrames</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab2.html#part-1-read-and-parse-the-initial-dataset">Part 1: Read and parse the initial dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#a-load-and-check-the-data">1a) Load and check the data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#b-using-labeledpoint">1b) Using LabeledPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#visualization-1-features">Visualization 1: Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#c-find-the-range">1c) Find the range</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#d-shift-labels">1d) Shift labels</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#visualization-2-shifting-labels">Visualization 2: Shifting labels</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#e-training-validation-and-test-sets">1e) Training, validation, and test sets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab2.html#part-2-create-and-evaluate-a-baseline-model">Part 2: Create and evaluate a baseline model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#a-average-label">2a) Average label</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#b-root-mean-squared-error">2b) Root mean squared error</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#c-training-validation-and-test-rmse">2c) Training, validation and test RMSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#visualization-3-predicted-vs-actual">Visualization 3: Predicted vs. actual</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab2.html#part-3-train-via-gradient-descent-and-evaluate-a-linear-regression-model">Part 3: Train (via gradient descent) and evaluate a linear regression model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#a-gradient-summand">3a) Gradient summand</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#b-use-weights-to-make-predictions">3b) Use weights to make predictions</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#c-gradient-descent">3c) Gradient descent</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#d-train-the-model">3d) Train the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#visualization-4-training-error">Visualization 4: Training error</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab2.html#part-4-train-using-sparkml-and-perform-grid-search">Part 4: Train using SparkML and perform grid search</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#a-linearregression">4a) LinearRegression</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#b-transform">4b) Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#c-evaluate-rmse">4c) Evaluate RMSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#d-grid-search">4d) Grid search</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#visualization-5-best-model-s-predictions">Visualization 5: Best model&#8217;s predictions</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#visualization-6-hyperparameter-heat-map">Visualization 6: Hyperparameter heat map</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab2.html#part-5-add-interactions-between-features">Part 5: Add interactions between features</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#a-add-2-way-interactions">5a) Add 2-way interactions</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#b-build-interaction-model">5b) Build interaction model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#c-evaluate-interaction-model-on-test-data">5c) Evaluate interaction model on test data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab2.html#d-use-a-pipeline-to-create-the-interaction-model">5d) Use a pipeline to create the interaction model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab3.html">cs120_lab3_ctr_df</a></li>
<li class="toctree-l2"><a class="reference internal" href="cs120_lab4.html">cs120 - PCA on Neuroscience Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab4.html#work-through-the-steps-of-pca-on-a-sample-dataset">Work through the steps of PCA on a sample dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-1-two-dimensional-gaussians">Visualization 1: Two-dimensional Gaussians</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#a-interpreting-pca">1a) Interpreting PCA</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#b-sample-covariance-matrix">1b) Sample covariance matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#c-covariance-function">1c) Covariance Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#d-eigendecomposition">1d) Eigendecomposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#e-pca-scores">1e) PCA scores</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab4.html#write-a-pca-function-and-evaluate-pca-on-sample-datasets">Write a PCA function and evaluate PCA on sample datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#a-pca-function">2a) PCA function</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#b-pca-on-data-random">2b) PCA on data_random</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-2-pca-projection">Visualization 2: PCA projection</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-3-three-dimensional-data">Visualization 3: Three-dimensional data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#c-3d-to-2d">2c) 3D to 2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-4-2d-representation-of-3d-data">Visualization 4: 2D representation of 3D data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#d-variance-explained">2d) Variance explained</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab4.html#parse-inspect-and-preprocess-neuroscience-data-then-perform-pca">Parse, inspect, and preprocess neuroscience data then perform PCA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#a-load-neuroscience-data">3a) Load neuroscience data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#b-parse-the-data">3b) Parse the data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#c-min-and-max-fluorescence">3c) Min and max fluorescence</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-5-pixel-intensity">Visualization 5: Pixel intensity</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#d-fractional-signal-change">3d) Fractional signal change</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-6-normalized-data">Visualization 6: Normalized data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#e-pca-on-the-scaled-data">3e) PCA on the scaled data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-7-top-two-components-as-images">Visualization 7: Top two components as images</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-8-top-two-components-as-one-image">Visualization 8: Top two components as one image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cs120_lab4.html#feature-based-aggregation-and-pca">Feature-based aggregation and PCA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#a-aggregation-using-arrays">(4a) Aggregation using arrays</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#b-recreate-with-np-tile-and-np-eye">(4b) Recreate with np.tile and np.eye</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#c-recreate-with-np-kron">(4c) Recreate with np.kron</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#d-aggregate-by-time">(4d) Aggregate by time</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#e-obtain-a-compact-representation">(4e) Obtain a compact representation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-9-top-two-components-by-time">Visualization 9: Top two components by time</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#f-aggregate-by-direction">(4f) Aggregate by direction</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#g-compact-representation-of-direction-data">(4g) Compact representation of direction data</a></li>
<li class="toctree-l4"><a class="reference internal" href="cs120_lab4.html#visualization-10-top-two-components-by-direction">Visualization 10: Top two components by direction</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="top-pyspark.html">PySpark Notes (<code class="docutils literal"><span class="pre">top-pyspark.rst</span></code>)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="pyspark-snippet.html">1 <code class="docutils literal"><span class="pre">pyspark-snippet.rst</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#data-from-application-examples-on-db-workspace">1.1 Data from <em>Application Examples</em> on DB Workspace</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#list-out-datasets-important">1.1.1 List out datasets (Important)</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#create-sample-json-file">1.1.2 Create sample JSON file</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#tables">1.1.3 Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#random-data-io">1.1.4 Random data-io</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#diamonds">1.1.5 Diamonds</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#february-2015-english-wikipedia-clickstream-data">1.1.6 February 2015 English Wikipedia Clickstream data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#dbf">1.2 DBF</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#modules">1.3 Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#spark-notebook-helpers-library-for-databricks">1.4 spark_notebook_helpers library for Databricks</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#create-toy-dataset">1.5 Create toy dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#print-rdd-per-item">1.6 Print RDD per item</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#databrick-helper-function-displaying-all-dfs-in-the-notebook">1.7 Databrick helper function displaying all DFs in the notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#get-shape-of-df-gotta-be-a-better-way">1.8 Get shape of DF (gotta be a better way)</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#random-snippets">1.9 Random snippets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#print-dataframes-in-my-workspace-super-ad-hoc">1.9.1 print dataframes in my workspace (super-ad-hoc)</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#rename-column">1.9.2 Rename column</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#dbutils">1.10 dbutils</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#random-from-spark-essentials-spark-summit-2016">1.11 Random from Spark Essentials (Spark Summit 2016)</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-snippet.html#spark-for-data-scientists">1.12 Spark for Data Scientists</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#tax-data">1.12.1 Tax Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#farmer-s-market-data">1.12.2 Farmer&#8217;s market data</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#run-some-sql-create-tables">1.12.3 Run some sql, create tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-snippet.html#cache-table-in-sql-or-sqlcontext">1.12.4 cache table in SQL or sqlContext</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pyspark-practice.html">2 <code class="docutils literal"><span class="pre">pyspark-practice.rst</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#basics-dfs">2.1 Basics DFs</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#udfs">2.2 UDFs</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#sorting">2.3 Sorting</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#create-df-from-list-of-tuples">2.4 Create DF from list of tuples</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#groupby">2.5 groupby</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#practice-with-faker-data">2.6 Practice with faker data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-practice.html#little-refrehser-on-generators">2.6.1 Little refrehser on generators</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#register-table-to-use-sql">2.7 Register table to use SQL</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-practice.html#more">2.8 More</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pyspark-overflow.html">3 <code class="docutils literal"><span class="pre">pyspark-overflow.rst</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#how-to-get-a-value-from-the-row-object-in-spark-dataframe">3.1 How to get a value from the Row object in Spark Dataframe?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#how-to-add-a-constant-column-in-a-spark-dataframe">3.2 How to add a constant column in a Spark DataFrame?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#add-an-empty-column-to-spark-dataframe">3.3 Add an empty column to Spark DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#count-number-of-non-nan-entries-in-each-column-of-spark-dataframe">3.4 Count number of non-NaN entries in each column of Spark dataframe</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#use-simple-aggregation">3.4.1 Use simple aggregation</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#use-sql-null-semantics">3.4.2 Use SQL <code class="docutils literal"><span class="pre">NULL</span></code> semantics</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#in-fractions">3.4.3 In fractions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#updating-a-dataframe-column-in-spark">3.5 Updating a dataframe column in spark</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#how-do-i-add-a-new-column-to-spark-data-frame-pyspark">3.6 How do I add a new column to spark data frame (Pyspark)?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#use-literals-lit">3.6.1 Use literals <code class="docutils literal"><span class="pre">lit</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#transforming-an-existing-column">3.6.2 Transforming an existing column</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#using-join">3.6.3 Using <code class="docutils literal"><span class="pre">join</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#using-function-udf">3.6.4 Using function/UDF</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#how-to-change-dataframe-column-names-in-pyspark">3.7 How to change dataframe column names in pyspark?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#option-1-using-selectexpr">3.7.1 Option 1. Using selectExpr.</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#option-2-using-withcolumnrenamed">3.7.2 Option 2. Using <code class="docutils literal"><span class="pre">withColumnRenamed</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#using-alias">3.7.3 Using alias</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#using-sqlcontext-sql">3.7.4 Using <code class="docutils literal"><span class="pre">sqlContext.sql</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#pyspark-dataframes-way-to-enumerate-without-converting-to-pandas">3.8 PySpark DataFrames - way to enumerate without converting to Pandas?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#dividing-two-columns-from-a-different-df">3.9 Dividing two columns from a different DF</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-overflow.html#ones-i-just-bookmarked-for-future-reference">3.10 Ones I just bookmarked for future reference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyspark-overflow.html#reshaping-pivoting-data-in-spark-rdd-and-or-spark-dataframes">3.10.1 Reshaping/Pivoting data in Spark RDD and/or Spark DataFrames</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="">4 Spark Programming Guide DataFrames (<code class="docutils literal"><span class="pre">apache-prog-guide-df</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">4.1 Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sql">4.1.1 SQL</a></li>
<li class="toctree-l4"><a class="reference internal" href="#datasets-and-dataframes">4.1.2 Datasets and DataFrames</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#datasets">4.1.2.1 Datasets</a></li>
<li class="toctree-l5"><a class="reference internal" href="#dataframe">4.1.2.2 DataFrame</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#getting-started">4.2 Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#starting-point-sparksession">4.2.1 Starting Point: <code class="docutils literal"><span class="pre">SparkSession</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#creating-dataframes">4.2.2 Creating DataFrames</a></li>
<li class="toctree-l4"><a class="reference internal" href="#untyped-dataset-operations-aka-dataframe-operations">4.2.3 Untyped Dataset Operations (aka DataFrame Operations)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-sql-queries-programmatically">4.2.4 Running SQL Queries Programmatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="#creating-datasets-only-in-scala-java">4.2.5 Creating Datasets (only in Scala/Java)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#interoperating-with-rdds">4.2.6 Interoperating with RDDs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#inferring-the-schema-using-reflection">4.2.6.1 Inferring the Schema Using Reflection</a></li>
<li class="toctree-l5"><a class="reference internal" href="#programmatically-specifying-the-schema">4.2.6.2 Programmatically Specifying the Schema</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#data-sources">4.3 Data Sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="#generic-load-functions">4.4 Generic Load Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#default-parquet">4.4.1 Default (parquet)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#manually-specifying-options">4.4.2 Manually Specifying Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-sql-on-files-directly">4.4.3 Run SQL on files directly</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#generic-save-functions">4.5 Generic Save Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#save-modes">4.5.1 Save Modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#saving-to-persistent-tables">4.5.2 __Saving to Persistent Tables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#parquet-files">4.6 Parquet Files</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#loading-data-programmatically">4.6.1 Loading Data Programmatically</a></li>
<li class="toctree-l4"><a class="reference internal" href="#partition-discovery">4.6.2 __Partition Discovery</a></li>
<li class="toctree-l4"><a class="reference internal" href="#schema-merging">4.6.3 Schema Merging</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hive-metastore-parquet-conversion">4.6.4 __Hive metastore Parquet Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="#configuration">4.6.5 Configuration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#json-datasets">4.7 JSON Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hive-tables">4.8 Hive Tables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#interacting-with-different-versions-of-hive-metastore">4.8.1 __Interacting with Different Versions of Hive Metastore</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#jdbc-to-other-databases">4.9 __JDBC To Other Databases</a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning">4.10 Performance Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#caching-data-in-memory">4.10.1 Caching Data in Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="#other-configuration-options">4.10.2 Other Configuration Options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#distributed-sql-engine">4.11 Distributed SQL Engine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#running-the-thrift-jdbc-odbc-server">4.11.1 __Running the Thrift JDBC/ODBC server</a></li>
<li class="toctree-l4"><a class="reference internal" href="#running-the-spark-sql-cli">4.11.2 Running the Spark SQL CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#reference">4.12 Reference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#data-types">4.12.1 Data-Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nan-semantics">4.12.2 NaN Semantics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="databricks.html">5 Databrick Doc (<code class="docutils literal"><span class="pre">databricks.rst</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="databricks.html#ml-stuffs">5.1 ML Stuffs</a></li>
<li class="toctree-l3"><a class="reference internal" href="databricks.html#bunch-of-notebooks">5.2 Bunch of notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pyspark-local.html">PySpark on AWS (<code class="docutils literal"><span class="pre">pyspark-local</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pyspark-local.html#setting-up-aws-and-pyspark">Setting up AWS and PySpark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#create-iam-user-key">Create IAM user key</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#create-admin-group-and-user">Create admin group and user</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#setup-an-s3-bucket">Setup an S3 Bucket</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#create-wordcount-script-to-submit">Create wordcount script to submit</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#create-emr-cluster">Create EMR cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#run-spark-application-on-emr">Run Spark application on EMR</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pyspark-local.html#setup-pyspark-in-ipython-profile">Setup pyspark in ipython profile</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#finally-worked">Finally worked!</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#wrong-java-version">Wrong java version?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#pyspark-options-giving-errors">pyspark options giving errors...</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#update-scala">Update scala?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#rough-drafts">rough drafts</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pyspark-local.html#failed-windows-try">Failed Windows Try</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#windows">windows?</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark-local.html#retry-above-is-a-disaster">Retry, above is a disaster</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apache-ml-guide.html">MLLib - Main guide (<code class="docutils literal"><span class="pre">apache-ml-guide.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.pipeline-old.html">1 Pipeline-old (<code class="docutils literal"><span class="pre">pipeline-old</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#main-concepts-in-pipelines">1.1 Main concepts in Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#dataframe">1.2 DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#pipeline-components">1.3 Pipeline components</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#transformers">1.3.1 Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#estimators">1.3.2 Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#properties-of-pipeline-components">1.3.3 Properties of pipeline components</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#pipeline-transformers-and-estimators">1.4 Pipeline (transformers and estimators)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#how-it-works">1.4.1 How it works</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#details">1.4.2 Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#parameters">1.5 Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#saving-and-loading-pipelines">1.6 Saving and Loading Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#code-examples">1.7 Code Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#estimator-transformer-and-param">1.7.1 Estimator, Transformer, and Param</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#example-pipeline">1.7.2 Example: Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#example-model-selection-via-cv-scala">1.7.3 Example: model selection via CV (Scala)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.pipeline-old.html#example-model-selection-via-train-validation-split-scala">1.7.4 Example: model selection via train validation split (scala)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.et-fs.html">2 Extracting, transforming and selecting features (<code class="docutils literal"><span class="pre">et-fs</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.et-fs.html#feature-extractors">2.1 Feature Extractors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#tf-idf">2.1.1 TF-IDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#word2vec">2.1.2 Word2Vec</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#countvectorizer">2.1.3 CountVectorizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.et-fs.html#feature-transformers">2.2 Feature Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#tokenizer">2.2.1 Tokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#stopwordsremover">2.2.2 StopWordsRemover</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#n-gram">2.2.3 n-gram</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#binarizer">2.2.4 Binarizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#pca">2.2.5 PCA</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#polynomialexpansion">2.2.6 PolynomialExpansion</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#discrete-cosine-transform-dct">2.2.7 Discrete Cosine Transform (DCT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#stringindexer">2.2.8 StringIndexer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#indextostring">2.2.9 IndexToString</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#onehotencoder">2.2.10 OneHotEncoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#vectorindexer">2.2.11 VectorIndexer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#normalizer">2.2.12 Normalizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#standardscaler">2.2.13 StandardScaler</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#minmaxscaler">2.2.14 MinMaxScaler</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#maxabsscaler">2.2.15 MaxAbsScaler</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#bucketizer">2.2.16 Bucketizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#elementwiseproduct-bm">2.2.17 ElementwiseProduct (bm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#sqltransformer-bm">2.2.18 SQLTransformer (bm)</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#vectorassembler">2.2.19 VectorAssembler</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#quantilediscretizer">2.2.20 QuantileDiscretizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.et-fs.html#feature-selectors">2.3 Feature Selectors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#vectorslicer">2.3.1 VectorSlicer</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#rformula">2.3.2 RFormula</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.et-fs.html#chisqselector">2.3.3 ChiSqSelector</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.classification.html">3 Classification (<code class="docutils literal"><span class="pre">classification</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#logistic-regression">3.1 Logistic regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#decision-tree-classifier">3.2 Decision tree classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#random-forest-classifier">3.3 Random forest classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#gradient-boosted-tree-classifier">3.4 Gradient-boosted tree classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#multilayer-perceptron-classifier">3.5 Multilayer perceptron classifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#one-vs-rest-classifier-a-k-a-one-vs-all">3.6 One-vs-Rest classifier (a.k.a. One-vs-All)</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.classification.html#naive-bayes">3.7 Naive Bayes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.regression.html">4 Regression (<code class="docutils literal"><span class="pre">regression.rst</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#linear-regression">4.1 Linear regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#generalized-linear-regression">4.2 Generalized linear regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.regression.html#available-families">4.2.1 Available families</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#decision-tree-regression">4.3 Decision tree regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#random-forest-regression">4.4 Random forest regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#gradient-boosted-tree-regression">4.5 Gradient-boosted tree regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#survival-regression">4.6 Survival regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.regression.html#isotonic-regression">4.7 Isotonic regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.regression.html#examples">4.7.1 Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-guide.tree.html">5 Tree-based-methods (<code class="docutils literal"><span class="pre">tree.rst</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.tree.html#decision-trees">5.1 Decision trees</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.tree.html#inputs-and-outputs">5.1.1 Inputs and Outputs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-guide.tree.html#tree-ensembles">5.2 Tree Ensembles</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.tree.html#random-forests">5.2.1 Random Forests</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-guide.tree.html#gradient-boosted-trees-gbts">5.2.2 Gradient-Boosted Trees (GBTs)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apache-ml-rdd.html">MLLib: RDD-based API Guideline (<code class="docutils literal"><span class="pre">apache-ml-rdd</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-rdd.datatype.html">1 Data Types (<code class="docutils literal"><span class="pre">datatypes</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.datatype.html#local-vector">1.1 Local vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.datatype.html#labeled-point">1.2 Labeled point</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.datatype.html#local-matrix">1.3 Local matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.datatype.html#distributed-matrix">1.4 Distributed matrix</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.datatype.html#rowmatrix">1.4.1 RowMatrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.datatype.html#indexedrowmatrix">1.4.2 IndexedRowMatrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.datatype.html#coordinatematrix">1.4.3 CoordinateMatrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.datatype.html#blockmatrix">1.4.4 BlockMatrix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-rdd.stats.html">2 Basic Statistics (<code class="docutils literal"><span class="pre">stats</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#summary-statistics">2.1 Summary statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#correlations">2.2 Correlations</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#stratified-sampling">2.3 Stratified sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#hypothesis-testing">2.4 Hypothesis testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.stats.html#streaming-significance-testing">2.4.1 Streaming Significance Testing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#random-data-generation">2.5 Random data generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.stats.html#kernel-density-estimation">2.6 Kernel density estimation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apache-ml-rdd.eval.html">3 Evaluation metrics (<code class="docutils literal"><span class="pre">eval</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.eval.html#classification-model-evaluation">3.1 Classification model evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.eval.html#binary-classification">3.1.1 Binary classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.eval.html#multiclass-classification">3.1.2 Multiclass classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.eval.html#multilabel-classification">3.1.3 Multilabel classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="apache-ml-rdd.eval.html#ranking-systems">3.1.4 Ranking systems</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apache-ml-rdd.eval.html#regression-model-evaluation">3.2 Regression model evaluation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Table of Contents (Others)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../R/top-R.html">R Notes (<code class="docutils literal"><span class="pre">top-R.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../R/R-cookbook.html">R cookbook (<code class="docutils literal"><span class="pre">R-cookbook.rst</span></code>)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../R/r-cookbook-1-getting-started.html">1. Getting started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-1-getting-started.html#getting-help">Getting help</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-1-getting-started.html#help-search">help.search</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html">2. Some basics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#print-and-cat">print and cat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#setting-listing-and-removing-variables">setting, listing, and removing variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#create-vector-the-c-operator">Create vector - the <code class="docutils literal"><span class="pre">c(...)</span></code> operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#basic-statistics">Basic statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#create-sequences-seq-from-to-by-rep-arg-times-5">Create sequences (<code class="docutils literal"><span class="pre">:,</span> <span class="pre">seq(from,to,by),</span> <span class="pre">rep(arg,times=5)</span></code>)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#vector-comparison-elementwise-comparison">Vector comparison (elementwise comparison)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#vector-indexing-and-slicing">Vector indexing and slicing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#naming-vector-elements-gives-another-way-to-index">naming vector elements (gives another way to index)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#vector-arithmetic-elementwise">Vector arithmetic (elementwise...)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#some-special-operator">Some special operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#warning-on-operator-precedence">Warning on operator precedence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-2-some-basics.html#defining-function">Defining function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../R/r-cookbook-11-lr-anova.html">11. Linear Regression and ANOVA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../R/r-cookbook-11-lr-anova.html#syntax-for-linear-regression">Syntax for linear regression</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../bash_wooledge/top-bash-wool.html">Bash wooledge (<code class="docutils literal"><span class="pre">top-bash-wool.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../bash_wooledge/special_char.html">1 Special Characters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bash_wooledge/param.html">2 Parameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/param.html#basic">2.1 Basic</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#always-double-quote-when-doing-pe-parameter-expansion">2.1.1 Always double-quote when doing PE (parameter expansion)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#char-needed-with-dealing-with-numerics">2.1.2 char needed with dealing with numerics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/param.html#special-parameters-and-variables">2.2 Special Parameters and Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#special-parameters">2.2.1 Special Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#special-variables-provided-by-the-shell">2.2.2 Special variables provided by the shell</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/param.html#pe-tricks-some-i-rarely-use">2.3 PE tricks (some I rarely use)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#summary-table">2.3.1 Summary table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#var">2.3.2 <code class="docutils literal"><span class="pre">${var}</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#var-word-use-default-value">2.3.3 <code class="docutils literal"><span class="pre">${var:-word}</span></code> (use default value)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#var-word-assign-default">2.3.4 <code class="docutils literal"><span class="pre">${var:=word}</span></code> (assign default)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#var-word-use-alternate-value">2.3.5 <code class="docutils literal"><span class="pre">${var:+word}</span></code> (use alternate value)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#var-offset-length-substring-expansion">2.3.6 <code class="docutils literal"><span class="pre">${var:offset:length}</span></code> (substring expansion)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#var-var-number-of-characters-or-array-items">2.3.7 <code class="docutils literal"><span class="pre">${#var}</span></code>, <code class="docutils literal"><span class="pre">${#var[&#64;]}</span></code> (number of characters or array items)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#var-pattern-delete-beginning-of-str-if-match">2.3.8 <code class="docutils literal"><span class="pre">${var#pattern}</span></code> (delete beginning of str if match)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/param.html#var-msg-print-msg-to-stderr">2.3.9 <code class="docutils literal"><span class="pre">${var:?msg}</span></code> (print msg to stderr)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../bash_wooledge/patterns.html">3 Patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/patterns.html#glob-patterns">3.1 Glob patterns</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/patterns.html#use-glob-not-ls-for-looping-over-files">3.1.1 Use glob, not ls for looping over files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/patterns.html#extended-globs-i-rather-use-regexp">3.2 Extended Globs (I rather use regexp)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/patterns.html#regular-expressions">3.3 Regular expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/patterns.html#brace-expansion">3.4 Brace Expansion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../bash_wooledge/tests.html">4 Tests</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/tests.html#exit-status-0-success-use">4.1 Exit status (0 = success)....use $?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/tests.html#control-operators-and">4.2 Control operators (&amp;&amp; and ||)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/tests.html#grouping-statements">4.3 Grouping statements {...;}</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/tests.html#use-case1-reporting-stderr-on-complex-test">4.3.1 Use-case1: reporting stderr on complex test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/tests.html#use-case2-redirect-input-to-a-group-of-statements">4.3.2 Use-case2: redirect input to a group of statements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bash_wooledge/tests.html#use-case3-error-handling">4.3.3 Use-case3: error handling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../bash_wooledge/conditionals.html">5 Conditionals</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/conditionals.html#conditional-blocks-if-test-and">5.1 Conditional Blocks (if, test and [[)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/conditionals.html#conditional-loops-while-until-and-for">5.2 Conditional Loops (while, until and for)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../bash_wooledge/conditionals.html#choices-case-and-select">5.3 Choices (case and select)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../sed/sed-tutorial.gnu.html">sed-tutorial-gnu (<code class="docutils literal"><span class="pre">sed-tutorial.gnu.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#execution-cycle-how-sed-works">Execution Cycle: How sed works</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#addresses-selecting-lines-with-sed">Addresses: Selecting lines with sed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#single-address-form">Single address form</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#two-address-form">Two address form</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#match-negation-via">Match negation via <code class="docutils literal"><span class="pre">!</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#regular-expressions-overview-of-regular-expression-syntax">Regular Expressions: Overview of regular expression syntax</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#common-commands-often-used-commands">Common Commands: Often used commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#the-s-command-sed-s-swiss-army-knife">The &#8220;s&#8221; Command: sed&#8217;s Swiss Army Knife</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#replacement">replacement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#flags">flags</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#other-commands-less-frequently-used-commands">Other Commands: Less frequently used commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.gnu.html#programming-commands-commands-for-sed-gurus">Programming Commands: Commands for sed gurus</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html">sed-tutorials-points (<code class="docutils literal"><span class="pre">sed-tutorial.tut</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#sed-workflow">Sed - workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#basic-syntax-and-examples">Basic syntax and examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#examples">Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#standard-options">Standard options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#gnu-specific-options">GNU specific options</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#loops-branches">Loops, Branches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#address-range-search-by-specifying-line-nums">Address range (search by specifying line-nums)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#p-syntax">&#8216;p&#8217; syntax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#m-n-syntax">&#8216;M,+n&#8217; syntax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#id1">&#8216;M,~n&#8217; syntax</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#pattern-range-search-for-simple-text-or-regexp-using-regex-syntax">Pattern range - search for simple-text or regexp using /regex/ syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#basic-commands-delete-read-write-append">Basic commands (delete, read, write, append)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#delete-command-address1-address2-d">Delete command [address1[,address2]]d</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#write-command-address1-address2-w-file">Write command [address1[,address2]]w file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#append-command-address-a">Append command [address]a</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#change-command-address1-address2-c">Change command [address1[,address2]]c</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#insert-command-address-i">Insert Command [address]i</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#translate-command-address1-address2-y-list-1-list-2">Translate command [address1[,address2]]y/list-1/list-2/</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#i-command">I command</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#quit-command-address-q">Quit Command [address]q</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#read-command-address-r-file">Read Command [address]r file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#exectuve-command-address1-address2-e-command">Exectuve Command [address1[,address2]]e [command]</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sed/sed-tutorial.tutorialspoints.html#miscellaneous-commands">Miscellaneous Commands</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../awk-tutorial/awk-tutorial.html">awk-tutorial (<code class="docutils literal"><span class="pre">awk-tutorial.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../awk-tutorial/awk-basic-structure.html">1 Basic structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../awk-tutorial/awk-essential-syntax.html">2 The Essential Syntax of AWK</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-essential-syntax.html#unary-arithmetic-operators">2.1 Unary arithmetic operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-essential-syntax.html#the-autoincrement-and-autodecrement-operators">2.2 The Autoincrement and Autodecrement Operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-essential-syntax.html#assignment-operators">2.3 Assignment Operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-essential-syntax.html#conditional-expressions">2.4 Conditional expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-essential-syntax.html#regular-expressions">2.5 Regular Expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-essential-syntax.html#and-or-not">2.6 And/Or/Not</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../awk-tutorial/awk-summary-commands.html">3 Summary of AWK Commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="../awk-tutorial/awk-builtin-vars.html">4 AWK Built-in Variables</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-builtin-vars.html#fs-the-input-field-separator-variable">4.1 FS - The Input Field Separator Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-builtin-vars.html#ofs-the-output-field-separator-variable">4.2 OFS - The Output Field Separator Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-builtin-vars.html#nf-the-number-of-fields-variable">4.3 NF - The Number of Fields Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-builtin-vars.html#nr-the-number-of-records-variable">4.4 NR - The Number of Records Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-builtin-vars.html#rs-the-record-separator-variable">4.5 RS - The Record Separator Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-builtin-vars.html#ors-the-output-record-separator-variable">4.6 ORS - The Output Record Separator Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tutorial/awk-builtin-vars.html#filename-the-current-filename-variable">4.7 FILENAME - The Current Filename Variable</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../awk-tp.html">Awk Tutorials Points (<code class="docutils literal"><span class="pre">awk-tp.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../awk-ss64.html">1 Whirlwind tour from ss64</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../awk-ss64.html#basic-syntax">1.1 Basic syntax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-ss64.html#awk-patterns">1.2 awk-patterns</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-ss64.html#variable-names-that-are-predefined">1.3 Variable names that are predefined</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-ss64.html#examples">1.4 Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-ss64.html#complex-examples">1.5 Complex examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../awk-grymoire.html">2 Tables from grymoire</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../awk-grymoire.html#arithmetic-expressions">2.1 Arithmetic expressions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#binary-operator">2.1.1 Binary operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#assignment-operator">2.1.2 Assignment operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#conditional-expressions">2.1.3 Conditional expressions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#regexp">2.1.4 Regexp</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../awk-grymoire.html#summary-of-awk-commands">2.2 Summary of AWK commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-grymoire.html#build-int-awk-variables">2.3 Build-int AWK variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-grymoire.html#printf-formatting">2.4 printf - formatting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#syntax">2.4.1 syntax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#escape-sequences">2.4.2 Escape sequences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#format-specifiers">2.4.3 Format specifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#width-specify-minimum-field-size">2.4.4 Width - specify minimum field size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#my-own-example-use-to-left-justify-string-in-s">2.4.5 my own example (use &#8220;-&#8221; to left justify string in %s)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#examples-of-complex-formatting">2.4.6 Examples of complex formatting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#explicit-file-output">2.4.7 Explicit file output</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../awk-grymoire.html#flow-control-with-next-and-exit">2.5 Flow Control with next and exit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-grymoire.html#awk-numerical-functions">2.6 AWK Numerical Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-grymoire.html#awk-string-functions">2.7 AWK String functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#split-demo">2.7.1 split demo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#gsub-demo">2.7.2 gsub demo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../awk-grymoire.html#match-demo">2.7.3 match demo</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../awk-tp.workflow.html">3 awk-workflow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../awk-tp.workflow.html#the-begin-body-end-block">3.1 The BEGIN, body, END block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tp.workflow.html#first-example-on-marks-txt-file">3.2 First example on marks.txt file</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../awk-tp.basic-syntax.html">4 AWK Basic Syntax</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../awk-tp.basic-syntax.html#awk-help">4.1 awk &#8211;help</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tp.basic-syntax.html#awk-in-the-terminal-or-program-file">4.2 AWK in the terminal or Program file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tp.basic-syntax.html#v-option">4.3 -v option</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tp.basic-syntax.html#dump-global-variables">4.4 dump global variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../awk-tp.basic-syntax.html#profile-file-to-create-pretty-printed-script-file">4.5 &#8211;profile[=file] to create pretty-printed script file</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../awk-tp.basic-examples.html">5 AWK &#8211; Basic Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../top-sqlite.html">SQL notes (<code class="docutils literal"><span class="pre">top-sqlite.rst</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../sqlite.tutpoint.html">1 SQLite notes from tutorialpoint</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.1_commands_overview.html">1.1 SQLite commands overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.1_commands_overview.html#ddl-data-definition-language">1.1.1 DDL (data definition language)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.1_commands_overview.html#dml-data-manipulation-language">1.1.2 DML (Data manipulation language)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.1_commands_overview.html#dql-data-query-language">1.1.3 DQL (data query language)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.2_unsupported_commands.html">1.2 Unsupported features in SQLite</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.3_sqlite_commands.html">1.3 sqlite commands</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.3_sqlite_commands.html#the-dot-commands-from-sqlite">1.3.1 the <em>dot</em> commands from sqlite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.3_sqlite_commands.html#show-see-default-settings">1.3.2 show &#8211; see default settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.3_sqlite_commands.html#format-output-with-header-mode-timer">1.3.3 Format output with (header, mode, timer)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.3_sqlite_commands.html#the-sqlite-master-table">1.3.4 The sqlite_master Table</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html">1.4 SQLite syntax (a whirl-wind tour)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#case-sensitivity">1.4.1 Case Sensitivity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#comments">1.4.2 Comments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#sqlite-statements-and-clause">1.4.3 SQLite Statements and Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#create-table">1.4.4 CREATE TABLE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#create-trigger">1.4.5 CREATE TRIGGER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#group-by">1.4.6 GROUP BY</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#having">1.4.7 HAVING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#pragma">1.4.8 PRAGMA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.4_sqlite_syntax.html#update">1.4.9 UPDATE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.5_datatype.html">1.5 SQLite Data Type</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.5_datatype.html#sqlite-storage-classes">1.5.1 SQLite Storage Classes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.5_datatype.html#sqlite-affinity-type">1.5.2 SQLite Affinity Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.5_datatype.html#sqlite-affinity-and-type-names">1.5.3 SQLite Affinity and Type Names</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.5_datatype.html#date-and-time-datatype">1.5.4 Date and Time Datatype</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html">1.6 SQLite DDL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html#create-database">1.6.1 CREATE Database</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html#attach-database">1.6.2 ATTACH Database</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html#basic-syntax">1.6.2.1 Basic syntax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html#demo">1.6.2.2 Demo</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html#detach-database">1.6.3 DETACH Database</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html#example">1.6.3.1 Example</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html#create-table">1.6.4 CREATE Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.6_sqlite_DDL.html#drop-table">1.6.5 DROP Table</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_DML.html">1.7 SQLite DML</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_DML.html#insert-query">1.7.1 INSERT Query</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_DML.html#select-query">1.7.2 SELECT Query</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_DML.html#update-query">1.7.3 UPDATE Query</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_DML.html#delete-query">1.7.4 DELETE Query</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html">1.8 SQLite clauses</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#where-clause">1.8.1 WHERE Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#and-or-clause">1.8.2 AND, OR Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#like-clause">1.8.3 LIKE Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#glob-clause">1.8.4 GLOB Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#limit-clause">1.8.5 LIMIT Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#having-clause">1.8.6 HAVING Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#unions-clause">1.8.7 UNIONS Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#order-by-clause">1.8.8 ORDER BY Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#group-by-clause">1.8.9 GROUP BY Clause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite.tutpoint.7_sqlite_clauses.html#distinct-clause-keyword">1.8.10 DISTINCT Clause/keyword</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.8_sqlite_expressions.html">1.9 SQLite Expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite.tutpoint.8_sqlite_operators.html">1.10 SQLite Operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_5.html">1.11 SQLite - useful functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite_5.html#summary-of-key-functions">1.11.1 Summary of key functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite_5.html#examples">1.11.2 Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sqlite_doc.html">2 Bunch of stuffs from the official doc</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_doc.html#command-line-shell-for-sqlite-incomplete">2.1 Command Line Shell for SQLite (incomplete)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite_doc.html#semicolon-to-indicate-end-of-sql-command">2.1.1 Semicolon to indicate end of SQL command</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite_doc.html#dot-commands-special-commands-to-sqlite3">2.1.2 dot-commands (special commands to sqlite3)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite_doc.html#todo">2.1.3 todo</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_doc.html#sql-syntax-link-only">2.2 SQL Syntax (link only)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_doc.html#sql-keywords-link-only">2.3 SQL Keywords (link only)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_doc.html#datatypes-in-sqlite-version3-todo">2.4 Datatypes in SQLite Version3 (todo)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_doc.html#core-functions-todo">2.5 Core functions (todo)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_doc.html#agg-functions">2.6 Agg functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_doc.html#data-and-time-functions">2.7 Data and time functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sqlite_doc.html#timestring">2.7.1 timestring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite_doc.html#modifiers">2.7.2 modifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sqlite_doc.html#examples">2.7.3 Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sqlite_doc.html#json-just-read">2.8 JSON (just read)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../sql_wiki.html">3 Random jumbles from wikipedia pertaining to Database concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../sql_wiki.html#data-integrity">3.1 Data Integrity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sql_wiki.html#ddl-dml-dcl">3.2 DDL, DML, DCL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#data-definition-language-ddl">3.2.1 Data definition language (DDL)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#data-manipulation-language-dml">3.2.2 Data Manipulation Language (DML)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#data-control-language-dcl">3.2.3 Data Control Language (DCL)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sql_wiki.html#acid">3.3 ACID</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#atomicity">3.3.1 Atomicity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#consistency">3.3.2 Consistency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#isolation">3.3.3 Isolation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#durability">3.3.4 Durability</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sql_wiki.html#jumpled-articles">3.4 Jumpled articles</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#consistency-model">3.4.1 Consistency model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#cap-theorem-aka-brewer-s-theorem">3.4.2 CAP Theorem (aka Brewer&#8217;s Theorem)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#database-transaction">3.4.3 Database transaction</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sql_wiki.html#database-normalization">3.5 Database normalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sql_wiki.html#database-schema">3.6 Database Schema</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#logical-schema">3.6.1 Logical schema</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#physical-schema">3.6.2 Physical schema</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#conceptual-schema">3.6.3 Conceptual schema</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sql_wiki.html#three-schema-approach">3.6.4 Three-schema approach</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../sql_wiki.html#bunch-of-jumbled-links">3.7 Bunch of jumbled links</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cs-computer.html">Random computer science notes (<code class="docutils literal"><span class="pre">cs-computer</span></code>)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../cs-computer.unix.html">Unix-related</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cs-computer.unix.html#terminal-shell-tty-console-the-difference">terminal, shell, tty, console...the difference?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../cs-computer.network.html">Network notes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cs-computer.network.html#http-messages">HTTP messages</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cs-computer.network.html#random-overflows">Random overflows</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Coding Notebook</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          













<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="top-pyspark.html">PySpark Notes (<code class="docutils literal"><span class="pre">top-pyspark.rst</span></code>)</a> &raquo;</li>
        
      <li>4 Spark Programming Guide DataFrames (<code class="docutils literal"><span class="pre">apache-prog-guide-df</span></code>)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/pyspark/apache-prog-guide-df.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="spark-programming-guide-dataframes-apache-prog-guide-df">
<h1>4 Spark Programming Guide DataFrames (<code class="docutils literal"><span class="pre">apache-prog-guide-df</span></code>)</h1>
<p><a class="reference external" href="http://spark.apache.org/docs/latest/sql-programming-guide.html">http://spark.apache.org/docs/latest/sql-programming-guide.html</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">TimeStamp:</th><td class="field-body">09-05-2016 (00:55)</td>
</tr>
</tbody>
</table>
<div class="contents local topic" id="contents">
<p class="topic-title first"><cite>Contents</cite></p>
<ul class="simple">
<li><a class="reference internal" href="#overview" id="id1">Overview</a></li>
<li><a class="reference internal" href="#getting-started" id="id2">Getting Started</a></li>
<li><a class="reference internal" href="#data-sources" id="id3">Data Sources</a></li>
<li><a class="reference internal" href="#generic-load-functions" id="id4">Generic Load Functions</a></li>
<li><a class="reference internal" href="#generic-save-functions" id="id5">Generic Save Functions</a></li>
<li><a class="reference internal" href="#parquet-files" id="id6">Parquet Files</a></li>
<li><a class="reference internal" href="#json-datasets" id="id7">JSON Datasets</a></li>
<li><a class="reference internal" href="#hive-tables" id="id8">Hive Tables</a></li>
<li><a class="reference internal" href="#jdbc-to-other-databases" id="id9">__JDBC To Other Databases</a></li>
<li><a class="reference internal" href="#performance-tuning" id="id10">Performance Tuning</a></li>
<li><a class="reference internal" href="#distributed-sql-engine" id="id11">Distributed SQL Engine</a></li>
<li><a class="reference internal" href="#reference" id="id12">Reference</a></li>
</ul>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Below is incomplete; I only took out codes that are informative.</p>
<p class="last">I did create a <em>skeleton</em> of TOC though.</p>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id1">4.1 Overview</a></h2>
<ul class="simple">
<li>Spark SQL is a Spark module for <strong>structured</strong> data processing.</li>
<li>Spark SQL uses the extra information from the <strong>structure</strong> to perform extra optimizations (so more optimized the basic <code class="docutils literal"><span class="pre">Spark</span> <span class="pre">RDD</span> <span class="pre">API</span></code>).</li>
<li>Spark SQL also has an API that&#8217;s portable over languages (Scala, Java, Python, R)</li>
</ul>
<p>All of the examples on this page use sample data included in the Spark distribution and can be run in the <code class="docutils literal"><span class="pre">spark-shell</span></code>, <code class="docutils literal"><span class="pre">pyspark</span> <span class="pre">shell</span></code>, or <code class="docutils literal"><span class="pre">sparkR</span> <span class="pre">shell</span></code>.</p>
<div class="section" id="sql">
<h3>4.1.1 SQL</h3>
<p>One use of Spark SQL is to execute <strong>SQL queries</strong>.</p>
<ul class="simple">
<li>Spark SQL can also be used to read data from an <strong>existing Hive installation</strong>.<ul>
<li>See the <a class="reference internal" href="#pyspark-proguide-hive-tables"><span>Hive Tables section</span></a> for details on how to configure this feature.</li>
</ul>
</li>
<li>When running SQL from within another programming language the results will be returned as a Dataset/DataFrame.</li>
<li>You can also interact with the SQL interface using the command-line or over JDBC/ODBC.</li>
</ul>
</div>
<div class="section" id="datasets-and-dataframes">
<h3>4.1.2 Datasets and DataFrames</h3>
<div class="section" id="datasets">
<h4>4.1.2.1 Datasets</h4>
<p>A <strong>Dataset</strong> is a distributed collection of data.</p>
<ul class="simple">
<li>Dataset is a new interface added in Spark 1.6 that provides the benefits of RDDs with the benefits of Spark SQL&#8217;s optimized execution engine.<ul>
<li><strong>Pros of RDDs</strong>: strong typing, ability to use powerful lambda functions</li>
</ul>
</li>
<li>A Dataset can be constructed from <strong>JVM objects</strong> and then manipulated using <strong>functional transformations</strong> (map, flatMap, filter, etc.).</li>
<li>The <code class="docutils literal"><span class="pre">Dataset</span> <span class="pre">API</span></code> is available in Scala and Java.</li>
</ul>
<div class="admonition important">
<p class="first admonition-title">Important</p>
<p>Python does not have the support for the Dataset API.</p>
<p class="last">But due to Python&#8217;s dynamic nature, many of the benefits of the Dataset API are already available (i.e. you can access the field of a row by name naturally row.columnName). The case for R is similar.</p>
</div>
</div>
<div class="section" id="dataframe">
<h4>4.1.2.2 DataFrame</h4>
<p>A <strong>DataFrame</strong> is a Dataset organized into named columns.</p>
<ul class="simple">
<li>It is conceptually equivalent to a table in a relational database or a data frame in R/Python, but with <strong>richer optimizations under the hood</strong>.</li>
<li>DataFrames can be constructed from a wide array of sources such as:<ul>
<li>structured data files,</li>
<li>tables in <strong>Hive</strong>,</li>
<li>external databases, or</li>
<li>existing RDDs.</li>
</ul>
</li>
<li>The <code class="docutils literal"><span class="pre">DataFrame</span> <span class="pre">API</span></code> is available in Scala, Java, Python, and R.</li>
<li>In <strong>Scala and Java</strong>, a DataFrame is represented by a Dataset of Rows.<ul>
<li>In the Scala API, DataFrame is simply a type alias of <code class="docutils literal"><span class="pre">Dataset[Row]</span></code>.</li>
<li>In the Java API, users need to use <code class="docutils literal"><span class="pre">Dataset&lt;Row&gt;</span></code> to represent a DataFrame.</li>
<li>Throughout this document, we will often refer to Scala/Java Datasets of Rows as DataFrames.</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="getting-started">
<h2><a class="toc-backref" href="#id2">4.2 Getting Started</a></h2>
<div class="admonition important">
<p class="first admonition-title">Important</p>
<p class="last">Find full example code at &#8220;<code class="docutils literal"><span class="pre">examples/src/main/python/sql.py</span></code>&#8221; in the Spark repo.</p>
</div>
<div class="section" id="starting-point-sparksession">
<h3>4.2.1 Starting Point: <code class="docutils literal"><span class="pre">SparkSession</span></code></h3>
<p>The entry point into all functionality in Spark is the <code class="docutils literal"><span class="pre">SparkSession</span></code> class.</p>
<ul class="simple">
<li>To create a basic SparkSession, just use <code class="docutils literal"><span class="pre">SparkSession.builder()</span></code>:</li>
<li>SparkSession in Spark 2.0 provides <strong>builtin support for Hive features</strong> including:<ul>
<li>the ability to write queries using <strong>HiveQL</strong>,</li>
<li>access to <strong>Hive UDFs</strong>, and</li>
<li>the ability to <strong>read data from Hive tables</strong>.</li>
</ul>
</li>
<li>you do not need to have an existing Hive setup to use these features (nice!).</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span>\
    <span class="o">.</span><span class="n">builder</span>\
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;PythonSQL&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.some.config.option&quot;</span><span class="p">,</span> <span class="s2">&quot;some-value&quot;</span><span class="p">)</span>\
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="creating-dataframes">
<h3>4.2.2 Creating DataFrames</h3>
<p>With a <code class="docutils literal"><span class="pre">SparkSession</span></code>, applications can create DataFrames from:</p>
<ul class="simple">
<li>an existing RDD,</li>
<li>from a Hive table, or</li>
<li>from Spark data sources (see <a class="reference internal" href="#pyspark-proguide-data-sources"><span>Data Sources</span></a>).</li>
</ul>
<p>Below is an JSON file example</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># spark is an existing SparkSession</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">)</span>

<span class="c1"># Displays the content of the DataFrame to stdout</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="untyped-dataset-operations-aka-dataframe-operations">
<h3>4.2.3 Untyped Dataset Operations (aka DataFrame Operations)</h3>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create the DataFrame</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Show the content of the DataFrame</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="go">age  name</span>
<span class="go">null Michael</span>
<span class="go">30   Andy</span>
<span class="go">19   Justin</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Print the schema in a tree format</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="go">root</span>
<span class="go">|-- age: long (nullable = true)</span>
<span class="go">|-- name: string (nullable = true)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Select only the &quot;name&quot; column</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="go">name</span>
<span class="go">Michael</span>
<span class="go">Andy</span>
<span class="go">Justin</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Select everybody, but increment the age by 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="go">name    (age + 1)</span>
<span class="go">Michael null</span>
<span class="go">Andy    31</span>
<span class="go">Justin  20</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Select people older than 21</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">21</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="go">age name</span>
<span class="go">30  Andy</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Count people by age</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;age&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="go">age  count</span>
<span class="go">null 1</span>
<span class="go">19   1</span>
<span class="go">30   1</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="running-sql-queries-programmatically">
<h3>4.2.4 Running SQL Queries Programmatically</h3>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM table&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="creating-datasets-only-in-scala-java">
<h3>4.2.5 Creating Datasets (only in Scala/Java)</h3>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Skipped...no python support</p>
</div>
</div>
<div class="section" id="interoperating-with-rdds">
<h3>4.2.6 Interoperating with RDDs</h3>
<p>Spark SQL supports two methods for converting existing RDDs into Datasets.</p>
<p>The first method uses <strong>reflection</strong> to infer the schema of an RDD that contains specific types of objects.</p>
<ul class="simple">
<li>This reflection based approach leads to <strong>more concise code</strong> and works well when you already know the schema while writing your Spark application.</li>
</ul>
<p>The second method for creating Datasets is through a <strong>programmatic interface</strong> that allows you to construct a schema and then apply it to an existing RDD.</p>
<ul class="simple">
<li>While this method is <strong>more verbose</strong>, it allows you to construct Datasets when the columns and their <strong>types are not known until runtime</strong>.</li>
</ul>
<div class="section" id="inferring-the-schema-using-reflection">
<span id="pyspark-proguide-schema-refl"></span><h4>4.2.6.1 Inferring the Schema Using Reflection</h4>
<p>Spark SQL can convert an RDD of <code class="docutils literal"><span class="pre">Row</span></code> objects to a DataFrame, <strong>inferring the datatypes</strong>.</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">Rows</span></code> are constructed by passing a <strong>list of key/value pairs</strong> as <code class="docutils literal"><span class="pre">kwargs</span></code> to the Row class (ie, pass a <code class="docutils literal"><span class="pre">dict</span></code>).<ul>
<li><strong>keys</strong>: define the column names of the table</li>
<li><strong>types</strong>: inferred by sampling the whole datase, similar to the inference that is performed on JSON files.</li>
</ul>
</li>
</ul>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="c1"># spark is an existing SparkSession.</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="c1"># Load a text file and convert each line to a Row.</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.txt&quot;</span><span class="p">)</span>
<span class="n">parts</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">))</span>
<span class="n">people</span> <span class="o">=</span> <span class="n">parts</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">Row</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">age</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>

<span class="c1"># Infer the schema, and register the DataFrame as a table.</span>
<span class="n">schemaPeople</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">people</span><span class="p">)</span>
<span class="n">schemaPeople</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>

<span class="c1"># SQL can be run over DataFrames that have been registered as a table.</span>
<span class="n">teenagers</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM people WHERE age &gt;= 13 AND age &lt;= 19&quot;</span><span class="p">)</span>

<span class="c1"># The results of SQL queries are RDDs and support all the normal RDD operations.</span>
<span class="n">teenNames</span> <span class="o">=</span> <span class="n">teenagers</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="k">for</span> <span class="n">teenName</span> <span class="ow">in</span> <span class="n">teenNames</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="n">teenName</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="programmatically-specifying-the-schema">
<h4>4.2.6.2 Programmatically Specifying the Schema</h4>
<p>When a dictionary of kwargs cannot be defined ahead of time, a DataFrame can be created programmatically with <strong>three steps</strong>.</p>
<ol class="arabic simple">
<li><strong>Create an RDD of tuples or lists</strong> from the original RDD;</li>
<li>Create the schema represented by a <code class="docutils literal"><span class="pre">StructType</span></code> matching the structure of <code class="docutils literal"><span class="pre">tuples</span></code> or <code class="docutils literal"><span class="pre">lists</span></code> in the RDD created in the step 1.</li>
<li>Apply the schema to the RDD via <code class="docutils literal"><span class="pre">createDataFrame</span></code> method provided by <code class="docutils literal"><span class="pre">SparkSession</span></code>.</li>
</ol>
<p>For Example:</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="c1"># Import SparkSession and data types</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># spark is an existing SparkSession.</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="c1"># Load a text file and convert each line to a tuple.</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.txt&quot;</span><span class="p">)</span>
<span class="n">parts</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">))</span>
<span class="n">people</span> <span class="o">=</span> <span class="n">parts</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()))</span>

<span class="c1"># The schema is encoded in a string.</span>
<span class="n">schemaString</span> <span class="o">=</span> <span class="s2">&quot;name age&quot;</span>

<span class="n">fields</span> <span class="o">=</span> <span class="p">[</span><span class="n">StructField</span><span class="p">(</span><span class="n">field_name</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">field_name</span> <span class="ow">in</span> <span class="n">schemaString</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span>

<span class="c1"># Apply the schema to the RDD.</span>
<span class="n">schemaPeople</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">people</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>

<span class="c1"># Creates a temporary view using the DataFrame</span>
<span class="n">schemaPeople</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>

<span class="c1"># SQL can be run over DataFrames that have been registered as a table.</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM people&quot;</span><span class="p">)</span>

<span class="c1"># The results of SQL queries are RDDs and support all the normal RDD operations.</span>
<span class="n">names</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
</div>
</div>
<div class="section" id="data-sources">
<span id="pyspark-proguide-data-sources"></span><h2><a class="toc-backref" href="#id3">4.3 Data Sources</a></h2>
<p>Spark SQL supports operating on a variety of data sources through the <strong>DataFrame interface</strong>.</p>
<p>A DataFrame can be operated on using <strong>relational transformations</strong> and can also be used to create a <strong>temporary view</strong>.</p>
<div class="admonition important">
<p class="first admonition-title">Important</p>
<p class="last">Registering a DataFrame as a temporary view allows you to run SQL queries over its data.</p>
</div>
<div class="admonition-section-overview admonition">
<p class="first admonition-title">Section overview</p>
<p class="last">This section describes the general methods for loading and saving data using the Spark Data Sources and then goes into specific options that are available for the built-in data sources.</p>
</div>
</div>
<div class="section" id="generic-load-functions">
<h2><a class="toc-backref" href="#id4">4.4 Generic Load Functions</a></h2>
<div class="section" id="default-parquet">
<h3>4.4.1 Default (parquet)</h3>
<p>The default data source (<code class="docutils literal"><span class="pre">parquet</span></code> unless otherwise configured by <code class="docutils literal"><span class="pre">spark.sql.sources.default</span></code>) will be used for all operations.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>From <a class="reference external" href="https://parquet.apache.org/">https://parquet.apache.org/</a></p>
<blockquote>
<div>Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.</div></blockquote>
<p class="last">Also see <a class="reference internal" href="#pyspark-proguide-parquet-files"><span>Parquet Files</span></a></p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/users.parquet&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;favorite_color&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;namesAndFavColors.parquet&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="manually-specifying-options">
<h3>4.4.2 Manually Specifying Options</h3>
<ul class="simple">
<li>Data sources are specified by their fully qualified name (i.e., <code class="docutils literal"><span class="pre">org.apache.spark.sql.parquet</span></code>), but for built-in sources you can also use their short names (<code class="docutils literal"><span class="pre">json,</span> <span class="pre">parquet,</span> <span class="pre">jdbc</span></code>)</li>
<li>DataFrames loaded from any data source type can be converted into other types using this syntax.</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s2">&quot;json&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;age&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;namesAndAges.parquet&quot;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="run-sql-on-files-directly">
<h3>4.4.3 Run SQL on files directly</h3>
<p>Instead of using read API to load a file into DataFrame and query it, you can also query that file directly with SQL.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM parquet.`examples/src/main/resources/users.parquet`&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="generic-save-functions">
<h2><a class="toc-backref" href="#id5">4.5 Generic Save Functions</a></h2>
<div class="section" id="save-modes">
<h3>4.5.1 Save Modes</h3>
<p>Save operations can optionally take a <code class="docutils literal"><span class="pre">SaveMode</span></code>, that specifies how to handle existing data if present.</p>
<ul class="simple">
<li>It is important to realize that these save modes <strong>do not utilize any locking</strong> and are <strong>not atomic</strong>.</li>
<li>Additionally, when performing an Overwrite, the data will be deleted before writing out the new data.</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Scala/JAVA</th>
<th class="head">Any Language</th>
<th class="head">Meaning</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal"><span class="pre">SaveMode.ErrorIfExists</span></code> (default)</td>
<td><code class="docutils literal"><span class="pre">&quot;error&quot;</span></code> (default)</td>
<td>When saving a DataFrame to a data source, if data already exists, an exception is expected to be thrown.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">SaveMode.Append</span></code></td>
<td><code class="docutils literal"><span class="pre">&quot;append&quot;</span></code></td>
<td>When saving a DataFrame to a data source, if data or table already exists, contents of the DataFrame are expected to be appended to existing data.</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">SaveMode.Overwrite</span></code></td>
<td><code class="docutils literal"><span class="pre">&quot;overwrite&quot;</span></code></td>
<td>Overwrite mode means that when saving a DataFrame to a data source, if data/table already exists, existing data is expected to be overwritten by the contents of the DataFrame.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">SaveMode.Ignore</span></code></td>
<td><code class="docutils literal"><span class="pre">&quot;ignore&quot;</span></code></td>
<td>Ignore mode means that when saving a DataFrame to a data source, if data already exists, the save operation is expected to not save the contents of the DataFrame and to not change the existing data. This is similar to a CREATE TABLE IF NOT EXISTS in SQL.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="saving-to-persistent-tables">
<h3>4.5.2 __Saving to Persistent Tables</h3>
<div class="admonition-todo admonition" id="index-0">
<p class="first admonition-title">Todo</p>
<p class="last">todo</p>
</div>
</div>
</div>
<div class="section" id="parquet-files">
<span id="pyspark-proguide-parquet-files"></span><h2><a class="toc-backref" href="#id6">4.6 Parquet Files</a></h2>
<p><a class="reference external" href="http://parquet.io/">Parquet</a> is a columnar format that is supported by many other data processing systems.</p>
<ul class="simple">
<li>Spark SQL provides support for both reading and writing Parquet files that automatically preserves the schema of the original data.</li>
<li>When writing Parquet files, all columns are automatically converted to be nullable for compatibility reasons.</li>
</ul>
<div class="section" id="loading-data-programmatically">
<h3>4.6.1 Loading Data Programmatically</h3>
<p>Using the data from the above example:</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="c1"># spark from the previous example is used in this example.</span>

<span class="n">schemaPeople</span> <span class="c1"># The DataFrame from the previous example.</span>

<span class="c1"># DataFrames can be saved as Parquet files, maintaining the schema information.</span>
<span class="n">schemaPeople</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;people.parquet&quot;</span><span class="p">)</span>

<span class="c1"># Read in the Parquet file created above. Parquet files are self-describing so the schema is preserved.</span>
<span class="c1"># The result of loading a parquet file is also a DataFrame.</span>
<span class="n">parquetFile</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;people.parquet&quot;</span><span class="p">)</span>

<span class="c1"># Parquet files can also be used to create a temporary view and then used in SQL statements.</span>
<span class="n">parquetFile</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;parquetFile&quot;</span><span class="p">);</span>
<span class="n">teenagers</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM parquetFile WHERE age &gt;= 13 AND age &lt;= 19&quot;</span><span class="p">)</span>
<span class="n">teenNames</span> <span class="o">=</span> <span class="n">teenagers</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="s2">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="k">for</span> <span class="n">teenName</span> <span class="ow">in</span> <span class="n">teenNames</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="n">teenName</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="partition-discovery">
<h3>4.6.2 __Partition Discovery</h3>
</div>
<div class="section" id="schema-merging">
<h3>4.6.3 Schema Merging</h3>
<p>Like ProtocolBuffer, Avro, and Thrift, Parquet also supports schema evolution. Users can start with a simple schema, and gradually add more columns to the schema as needed. In this way, users may end up with multiple Parquet files with different but mutually compatible schemas. The Parquet data source is now able to automatically detect this case and merge schemas of all these files.</p>
<p>Since schema merging is a relatively expensive operation, and is not a necessity in most cases, we turned it off by default starting from 1.5.0. You may enable it by
setting data source option mergeSchema to true when reading Parquet files (as shown in the examples below), or
setting the global SQL option spark.sql.parquet.mergeSchema to true.</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="c1"># Create a simple DataFrame, stored into a partition directory</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>\
                                   <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">Row</span><span class="p">(</span><span class="n">single</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">double</span><span class="o">=</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">df1</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;data/test_table/key=1&quot;</span><span class="p">)</span>

<span class="c1"># Create another DataFrame in a new partition directory,</span>
<span class="c1"># adding a new column and dropping an existing column</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
                                   <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">Row</span><span class="p">(</span><span class="n">single</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">triple</span><span class="o">=</span><span class="n">i</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">df2</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;data/test_table/key=2&quot;</span><span class="p">)</span>

<span class="c1"># Read the partitioned table</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;mergeSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s2">&quot;data/test_table&quot;</span><span class="p">)</span>
<span class="n">df3</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># The final schema consists of all 3 columns in the Parquet files together</span>
<span class="c1"># with the partitioning column appeared in the partition directory paths.</span>
<span class="c1"># root</span>
<span class="c1"># |-- single: int (nullable = true)</span>
<span class="c1"># |-- double: int (nullable = true)</span>
<span class="c1"># |-- triple: int (nullable = true)</span>
<span class="c1"># |-- key : int (nullable = true)</span>
</pre></div>
</div>
</div>
<div class="section" id="hive-metastore-parquet-conversion">
<h3>4.6.4 __Hive metastore Parquet Conversion</h3>
</div>
<div class="section" id="configuration">
<h3>4.6.5 Configuration</h3>
<p>Configuration of Parquet can be done using the <code class="docutils literal"><span class="pre">setConf</span></code> method on <code class="docutils literal"><span class="pre">SparkSession</span></code> or by running <code class="docutils literal"><span class="pre">SET</span> <span class="pre">key=value</span></code> commands using <code class="docutils literal"><span class="pre">SQL</span></code>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Property Name</th>
<th class="head">Default</th>
<th class="head">Meaning</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal"><span class="pre">spark.sql.parquet.binaryAsString</span></code></td>
<td>false</td>
<td>Some other Parquet-producing systems, in particular Impala, Hive, and older versions of Spark SQL, do not differentiate between binary data and strings when writing out the Parquet schema. This flag tells Spark SQL to interpret binary data as a string to provide compatibility with these systems.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">spark.sql.parquet.int96AsTimestamp</span></code></td>
<td>true</td>
<td>Some Parquet-producing systems, in particular Impala and Hive, store Timestamp into INT96. This flag tells Spark SQL to interpret INT96 data as a timestamp to provide compatibility with these systems.</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">spark.sql.parquet.cacheMetadata</span></code></td>
<td>true</td>
<td>Turns on caching of Parquet schema metadata. Can speed up querying of static data.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">spark.sql.parquet.compression.codec</span></code></td>
<td>gzip</td>
<td>Sets the compression codec use when writing Parquet files. Acceptable values include: uncompressed, snappy, gzip, lzo.</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">spark.sql.parquet.filterPushdown</span></code></td>
<td>true</td>
<td>Enables Parquet filter push-down optimization when set to true.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">spark.sql.hive.convertMetastoreParquet</span></code></td>
<td>true</td>
<td>When set to false, Spark SQL will use the Hive SerDe for parquet tables instead of the built in support.</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">spark.sql.parquet.mergeSchema</span></code></td>
<td>false</td>
<td>When true, the Parquet data source merges schemas collected from all data files, otherwise the schema is picked from the summary file or a random data file if no summary file is available.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="json-datasets">
<h2><a class="toc-backref" href="#id7">4.7 JSON Datasets</a></h2>
<div class="highlight-python"><div class="highlight"><pre><span></span>Spark SQL can automatically infer the schema of a JSON dataset and load it as a DataFrame. This conversion can be done using SparkSession.read.json on a JSON file.

Note that the file that is offered as a json file is not a typical JSON file. Each line must contain a separate, self-contained valid JSON object. As a consequence, a regular multi-line JSON file will most often fail.
</pre></div>
</div>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># A JSON dataset is pointed to by path.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The path can be either a single text file or a directory storing text files.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">people</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;examples/src/main/resources/people.json&quot;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The inferred schema can be visualized using the printSchema() method.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">people</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="go">root</span>
<span class="go">|-- age: long (nullable = true)</span>
<span class="go">|-- name: string (nullable = true)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Creates a temporary view using the DataFrame.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">people</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;people&quot;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># SQL statements can be run by using the sql methods provided by `spark`.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">teenagers</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT name FROM people WHERE age &gt;= 13 AND age &lt;= 19&quot;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Alternatively, a DataFrame can be created for a JSON dataset represented by</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># an RDD[String] storing one JSON object per string.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anotherPeopleRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="s1">&#39;{&quot;name&quot;:&quot;Yin&quot;,&quot;address&quot;:{&quot;city&quot;:&quot;Columbus&quot;,&quot;state&quot;:&quot;Ohio&quot;}}&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anotherPeople</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">jsonRDD</span><span class="p">(</span><span class="n">anotherPeopleRDD</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<div class="section" id="hive-tables">
<span id="pyspark-proguide-hive-tables"></span><h2><a class="toc-backref" href="#id8">4.8 Hive Tables</a></h2>
<p><a class="reference external" href="http://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables">http://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables</a></p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># spark is an existing SparkSession</span>

<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;CREATE TABLE IF NOT EXISTS src (key INT, value STRING)&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;LOAD DATA LOCAL INPATH &#39;examples/src/main/resources/kv1.txt&#39; INTO TABLE src&quot;</span><span class="p">)</span>

<span class="c1"># Queries can be expressed in HiveQL.</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;FROM src SELECT key, value&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
<div class="section" id="interacting-with-different-versions-of-hive-metastore">
<h3>4.8.1 __Interacting with Different Versions of Hive Metastore</h3>
<p><a class="reference external" href="http://spark.apache.org/docs/latest/sql-programming-guide.html#interacting-with-different-versions-of-hive-metastore">http://spark.apache.org/docs/latest/sql-programming-guide.html#interacting-with-different-versions-of-hive-metastore</a></p>
</div>
</div>
<div class="section" id="jdbc-to-other-databases">
<h2><a class="toc-backref" href="#id9">4.9 __JDBC To Other Databases</a></h2>
<p><a class="reference external" href="http://spark.apache.org/docs/latest/sql-programming-guide.html#jdbc-to-other-databases">http://spark.apache.org/docs/latest/sql-programming-guide.html#jdbc-to-other-databases</a></p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;jdbc&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">options</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s1">&#39;jdbc:postgresql:dbserver&#39;</span><span class="p">,</span> <span class="n">dbtable</span><span class="o">=</span><span class="s1">&#39;schema.tablename&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="performance-tuning">
<h2><a class="toc-backref" href="#id10">4.10 Performance Tuning</a></h2>
<div class="admonition important">
<p class="first admonition-title">Important</p>
<p>For some workloads it is possible to improve performance by either:</p>
<ol class="last arabic simple">
<li>caching data in memory, or by</li>
<li>turning on some experimental options.</li>
</ol>
</div>
<div class="section" id="caching-data-in-memory">
<h3>4.10.1 Caching Data in Memory</h3>
<p>Spark SQL can cache tables using an in-memory columnar format by calling <code class="docutils literal"><span class="pre">spark.cacheTable(&quot;tableName&quot;</span></code>) or <code class="docutils literal"><span class="pre">dataFrame.cache()</span></code>.</p>
<ul class="simple">
<li>Then Spark SQL will scan only required columns and will automatically tune compression to minimize memory usage and GC pressure.</li>
<li>You can call <code class="docutils literal"><span class="pre">spark.uncacheTable(&quot;tableName&quot;)</span></code> to remove the table from memory.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Configuration of in-memory caching can be done using the <code class="docutils literal"><span class="pre">setConf</span></code> method on <code class="docutils literal"><span class="pre">SparkSession</span></code> or by running <code class="docutils literal"><span class="pre">SET</span> <span class="pre">key=value</span></code> commands using SQL.</p>
</div>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Property Name</th>
<th class="head">Default</th>
<th class="head">Meaning</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal"><span class="pre">spark.sql.inMemoryColumnarStorage.compressed</span></code></td>
<td>true</td>
<td>When set to true Spark SQL will automatically select a compression codec for each column based on statistics of the data.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">spark.sql.inMemoryColumnarStorage.batchSize</span></code></td>
<td>10000</td>
<td>Controls the size of batches for columnar caching. Larger batch sizes can improve memory utilization and compression, but risk OOMs when caching data</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="other-configuration-options">
<h3>4.10.2 Other Configuration Options</h3>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">It is possible that these options will be deprecated in future release as more optimizations are performed automatically.</p>
</div>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Property Name</th>
<th class="head">Default</th>
<th class="head">Meaning</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal"><span class="pre">spark.sql.files.maxPartitionBytes</span></code></td>
<td>134217728 (128 MB)</td>
<td>The maximum number of bytes to pack into a single partition when reading files.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">spark.sql.files.openCostInBytes</span></code></td>
<td>4194304 (4 MB)</td>
<td>The estimated cost to open a file, measured by the number of bytes could be scanned in the same time. This is used when putting multiple files into a partition. It is better to over estimated, then the partitions with small files will be faster than partitions with bigger files (which is scheduled first).</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">spark.sql.autoBroadcastJoinThreshold</span></code></td>
<td>10485760 (10 MB)</td>
<td>Configures the maximum size in bytes for a table that will be broadcast to all worker nodes when performing a join. By setting this value to -1 broadcasting can be disabled. Note that currently statistics are only supported for Hive Metastore tables where the command ANALYZE TABLE &lt;tableName&gt; COMPUTE STATISTICS noscan has been run.</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">spark.sql.shuffle.partitions</span></code></td>
<td>200</td>
<td>Configures the number of partitions to use when shuffling data for joins or aggregations.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="distributed-sql-engine">
<h2><a class="toc-backref" href="#id11">4.11 Distributed SQL Engine</a></h2>
<p>Spark SQL can also act as a distributed query engine using its <code class="docutils literal"><span class="pre">JDBC/ODBC</span></code> or <strong>command-line interface</strong>.</p>
<p>In this mode, end-users or applications can interact with Spark SQL directly to run SQL queries, without the need to write any code.</p>
<div class="section" id="running-the-thrift-jdbc-odbc-server">
<h3>4.11.1 __Running the Thrift JDBC/ODBC server</h3>
</div>
<div class="section" id="running-the-spark-sql-cli">
<h3>4.11.2 Running the Spark SQL CLI</h3>
<p>The Spark SQL CLI is a convenient tool to run the Hive metastore service in local mode and execute queries input from the command line. Note that the Spark SQL CLI cannot talk to the Thrift JDBC server.</p>
<p>To start the Spark SQL CLI, run the following in the Spark directory:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>./bin/spark-sql
</pre></div>
</div>
<ul class="simple">
<li>To configure Hive, place your <code class="docutils literal"><span class="pre">hive-site.xml</span></code>, <code class="docutils literal"><span class="pre">core-site.xml</span></code> and <code class="docutils literal"><span class="pre">hdfs-site.xml</span></code> files in <code class="docutils literal"><span class="pre">conf/</span></code>.</li>
<li>You may run <code class="docutils literal"><span class="pre">./bin/spark-sql</span> <span class="pre">--help</span></code> for a complete list of all available options.</li>
</ul>
</div>
</div>
<div class="section" id="reference">
<h2><a class="toc-backref" href="#id12">4.12 Reference</a></h2>
<div class="section" id="data-types">
<h3>4.12.1 Data-Types</h3>
<p><a class="reference external" href="http://spark.apache.org/docs/latest/sql-programming-guide.html#data-types">http://spark.apache.org/docs/latest/sql-programming-guide.html#data-types</a></p>
</div>
<div class="section" id="nan-semantics">
<h3>4.12.2 NaN Semantics</h3>
<p>There is specially handling for not-a-number (NaN) when dealing with float or double types that does not exactly match standard floating point semantics.</p>
<div class="admonition important">
<p class="first admonition-title">Important</p>
<ul class="last simple">
<li><code class="docutils literal"><span class="pre">NaN</span> <span class="pre">=</span> <span class="pre">NaN</span></code> returns true.</li>
<li>In aggregations all NaN values are grouped together.</li>
<li>NaN is treated as a normal value in join keys.</li>
<li>NaN values go last when in ascending order, larger than any other numeric value.</li>
</ul>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="databricks.html" class="btn btn-neutral float-right" title="5 Databrick Doc (databricks.rst)" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="pyspark-overflow.html" class="btn btn-neutral" title="3 pyspark-overflow.rst" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
      Last updated on Oct 25, 2016.

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/copybutton.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>